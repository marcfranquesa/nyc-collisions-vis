{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f06624c8",
   "metadata": {},
   "source": [
    "# VI: First Practical Work\n",
    "\n",
    "**Authors:** Gerard Comas & Marc Franquesa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387d4716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using colaboratory, uncomment the following lines\n",
    "# !pip3 uninstall -y altair\n",
    "# !pip3 install altair==5.12.1\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "import geopandas as gpd\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "collisions = pd.read_csv(\"./processed-data/collisions.csv\")\n",
    "map_data = gpd.read_file(\"./processed-data/map.geojson\")\n",
    "weather = pd.read_csv(\"./processed-data/weather.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03d6d20",
   "metadata": {},
   "source": [
    "## Design and implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658aa12f-7ed0-4877-b5c6-db6a8ca28bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpful functions\n",
    "\n",
    "def before_covid(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df[df[\"AFTER COVID\"] == False]\n",
    "\n",
    "def after_covid(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df[df[\"AFTER COVID\"] == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c81d57-200f-44a8-ab17-dfbf7dc8c6d9",
   "metadata": {},
   "source": [
    "### 1. Are accidents more frequent during weekdays or weekends? Is there any difference between before COVID-19 and after?\n",
    "\n",
    "With an ambitious goal in mind, lets first plot the total collisions of each day of the week before COVID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f09065-124f-4ddb-8c96-91bd9b6aa0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_covid_day_count = before_covid(collisions).groupby([\"CRASH WEEKDAY\"]).size().reset_index(name=\"counts\")\n",
    "\n",
    "weekdayorder = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "\n",
    "alt.Chart(before_covid_day_count).mark_bar().encode(\n",
    "    x = alt.X(\"CRASH WEEKDAY:O\", sort=weekdayorder, axis=alt.Axis(title=\"Week Day\")),\n",
    "    y = alt.Y(\"counts:Q\", axis=alt.Axis(title=\"Collisions\"))\n",
    ").properties(\n",
    "    width=400\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf36cb6-f747-4b61-84dc-aa1b9e7094c2",
   "metadata": {},
   "source": [
    "Lets now make a grouped bar chart, separating before and after covid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803a7124-638c-4b81-8b44-e3811ff52f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "days_df = collisions.groupby([\"CRASH WEEKDAY\", \"AFTER COVID\"]).size().reset_index(name=\"counts\")\n",
    "\n",
    "before, after, all_time = \"Summer 2018 (Before Covid)\", \"Summer 2020 (After Covid)\", \"All\"\n",
    "\n",
    "days_df[\"MOMENT\"] = np.where(days_df[\"AFTER COVID\"], after, before)\n",
    "\n",
    "weekdayorder = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "\n",
    "opacity = 0.5\n",
    "\n",
    "colors = {\n",
    "    before: \"#fdc086\", # Before COVID\n",
    "    after: \"#7fc97f\", # After COVID\n",
    "    all_time: \"#beaed4\"\n",
    "}\n",
    "\n",
    "days_ch = alt.Chart(days_df).mark_bar(\n",
    "    opacity=opacity\n",
    ").encode(\n",
    "   x=alt.X(\"CRASH WEEKDAY:O\", axis=alt.Axis(labelAngle=-30, title=None), sort=weekdayorder),\n",
    "   xOffset=\"MOMENT:O\",\n",
    "   y=alt.Y(\"counts:Q\", axis=alt.Axis(title=\"Collisions\", grid=True)),\n",
    "   color=alt.Color(\"MOMENT:O\", scale=alt.Scale(domain=list(colors.keys()), range=list(colors.values())), legend=alt.Legend(title=None))\n",
    ")\n",
    "\n",
    "days_ch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49eec20a-7fe6-4f04-9198-428e6e6dee7d",
   "metadata": {},
   "source": [
    "Lets now add the average of before and after covid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6ef52c-bdc2-4bba-b10f-e4b6ed372b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "averages = alt.Chart(days_df).mark_rule(opacity=1).encode(\n",
    "    y=\"mean(counts):Q\",\n",
    "    size=alt.value(2),\n",
    "    color=\"MOMENT:O\"\n",
    ")\n",
    "\n",
    "averages + days_ch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544f66b6-a4e5-4538-8aac-96c391db20bd",
   "metadata": {},
   "source": [
    "Lets now separate the days of the week in two categories, weekdays and weekends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c80974a-6de2-4f37-996f-abe6e8b4a57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekdays = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\"]\n",
    "weekends = [\"Saturday\", \"Sunday\"]\n",
    "\n",
    "weekdays_df = days_df[days_df[\"CRASH WEEKDAY\"].isin(weekdays)]\n",
    "weekends_df = days_df[days_df[\"CRASH WEEKDAY\"].isin(weekends)]\n",
    "\n",
    "weekdays_ch = alt.Chart(weekdays_df).mark_bar(opacity=opacity).encode(\n",
    "   x=alt.X(\"CRASH WEEKDAY:O\", axis=alt.Axis(labelAngle=0, title=None), sort=weekdayorder),\n",
    "   xOffset=\"MOMENT:O\",\n",
    "   y=alt.Y(\"counts:Q\", axis=alt.Axis(title=\"Collisions / Means\", grid=True), scale=alt.Scale(domain=[0, 13000])),\n",
    "   color=alt.Color(\"MOMENT:O\", scale=alt.Scale(domain=list(colors.keys()), range=list(colors.values())))\n",
    ").properties(title=alt.Title(\"Weekdays\", fontSize=10, fontWeight=600))\n",
    "\n",
    "averages_weekday = alt.Chart(weekdays_df).mark_rule(opacity=1).encode(\n",
    "    y=\"mean(counts):Q\",\n",
    "    size=alt.value(2),\n",
    "    color=alt.Color(\"MOMENT:O\")\n",
    ")\n",
    "\n",
    "\n",
    "weekends_ch = alt.Chart(weekends_df).mark_bar(opacity=opacity).encode(\n",
    "   x=alt.X(\"CRASH WEEKDAY:O\", axis=alt.Axis(labelAngle=0, title=None), sort=weekdayorder),\n",
    "   xOffset=\"MOMENT:O\",\n",
    "   y=alt.Y(\n",
    "       \"counts:Q\",\n",
    "       axis=alt.Axis(title=None, labels=False, domain=False, ticks=False, grid=True),\n",
    "       scale=alt.Scale(domain=[0, 13000])\n",
    "   ),\n",
    "   color=alt.Color(\n",
    "       \"MOMENT:O\",\n",
    "       scale=alt.Scale(domain=list(colors.keys()), range=list(colors.values())),\n",
    "       legend=alt.Legend(title=None)\n",
    "   )\n",
    ").properties(title=alt.Title(\"Weekends\", fontSize=10, fontWeight=600))\n",
    "\n",
    "averages_weekend = alt.Chart(weekends_df).mark_rule(opacity=1).encode(\n",
    "    y=\"mean(counts):Q\",\n",
    "    size=alt.value(2),\n",
    "    color=\"MOMENT:O\"\n",
    ")\n",
    "\n",
    "\n",
    "# Played  around with the size to make it look good in the final viz\n",
    "q1 = ((weekdays_ch + averages_weekday).properties(width=318, height=300) | (weekends_ch + averages_weekend.properties(width=136, height=300)))\n",
    "\n",
    "q1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac0cf70-159a-4d17-b902-7fef0d9db59a",
   "metadata": {},
   "source": [
    "### 2. Is there any type of vehicle more prone to participate in accidents?\n",
    "Obviously, with the current data we have this is impossible, as cars are the most predominant vehicle by a large margin, meaning they will have the most collisions. Lets start off viewing this data with a simle bar plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886101f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles = collisions.groupby([\"VEHICLE\"]).size().reset_index(name=\"counts\")\n",
    "\n",
    "alt.Chart(vehicles).mark_bar().encode(\n",
    "    y=alt.Y(\"counts:Q\", axis=alt.Axis(title=\"Collisions\")),\n",
    "    x=alt.X(\"VEHICLE:O\", axis=alt.Axis(title=None, labelAngle=-30))\n",
    ").properties(\n",
    "    width=400\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0df887c",
   "metadata": {},
   "source": [
    "This confirms what we hypothesized earlier.\n",
    "\n",
    "The first idea we had was to create a parallel coordinate plane, where we would have the following plots:\n",
    "\n",
    "- Percentage of accidents\n",
    "- Percentage of circulation\n",
    "- Percentage of injuries\n",
    "- Percentage of deaths\n",
    "- Ratio of injuries/accident\n",
    "- Ratio of injuries/deaths\n",
    "\n",
    "However, in the provided data, we do not have the percentage of circulation for each vehicle, and searching on the internet, we have not found any dataset that can provide us with this information. Now, we will look at how the following plots are distributed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles = collisions[[\"VEHICLE\",\"NUMBER OF PERSONS INJURED\", \"NUMBER OF PERSONS KILLED\"]]\n",
    "vehicles = vehicles[vehicles[\"VEHICLE\"] != \"Unknown\"]\n",
    "\n",
    "vehicles = vehicles.groupby(\"VEHICLE\").agg({\n",
    "    \"VEHICLE\": \"count\",\n",
    "    \"NUMBER OF PERSONS INJURED\": \"sum\",\n",
    "    \"NUMBER OF PERSONS KILLED\": \"sum\"\n",
    "}).rename(columns={\"VEHICLE\": \"COLLISIONS\"}).reset_index()\n",
    "\n",
    "total_collisions = vehicles[\"COLLISIONS\"].sum()\n",
    "\n",
    "# Calcular el n√∫mero de accidentes por tipo de veh√≠culo\n",
    "vehicles[\"% COLLISIONS\"] = vehicles[\"COLLISIONS\"] / total_collisions * 100\n",
    "\n",
    "# Calcular el n√∫mero total de personas heridas y muertas en todos los accidentes\n",
    "total_injured = vehicles[\"NUMBER OF PERSONS INJURED\"].sum()\n",
    "total_killed = vehicles[\"NUMBER OF PERSONS KILLED\"].sum()\n",
    "\n",
    "# Calcular los porcentajes de personas heridas y muertas para cada tipo de veh√≠culo\n",
    "vehicles[\"% INJURED\"] = vehicles[\"NUMBER OF PERSONS INJURED\"] / total_injured * 100\n",
    "vehicles[\"% KILLED\"] = vehicles[\"NUMBER OF PERSONS KILLED\"] / total_killed * 100\n",
    "\n",
    "# Calcular los ratios de personas heridas y muertas por accidente para cada tipo de veh√≠culo\n",
    "vehicles[\"INJURED PER COLLISION\"] = vehicles[\"NUMBER OF PERSONS INJURED\"] / vehicles[\"COLLISIONS\"]\n",
    "vehicles[\"KILLED PER COLLISION\"] = vehicles[\"NUMBER OF PERSONS KILLED\"] / vehicles[\"COLLISIONS\"]\n",
    "\n",
    "vehicles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = alt.Chart(vehicles, width=800).transform_window(\n",
    "    index=\"count()\"\n",
    ").transform_fold(\n",
    "    [\"% COLLISIONS\", \"INJURED PER COLLISION\", \"KILLED PER COLLISION\"]\n",
    ").transform_joinaggregate(\n",
    "    min=\"min(value)\",\n",
    "    max=\"max(value)\",\n",
    "    groupby=[\"key\"]\n",
    ").transform_calculate(\n",
    "    norm_val=\"(datum.value - datum.min) / (datum.max - datum.min)\",\n",
    "    mid=\"(datum.min + datum.max) / 2\"\n",
    ")\n",
    "\n",
    "lines = base.mark_line(opacity=0.3).encode(\n",
    "    x=\"key:N\",\n",
    "    y= alt.Y(\"norm_val:Q\", axis=None),\n",
    "    color=\"VEHICLE:N\",\n",
    "    detail=\"index:N\",\n",
    "    opacity=alt.value(0.5)\n",
    ")\n",
    "\n",
    "rules = base.mark_rule(\n",
    "    color=\"#ccc\", tooltip=None\n",
    ").encode(\n",
    "    x=\"key:N\",\n",
    "    detail=\"count():Q\",\n",
    ") \n",
    "\n",
    "def ytick(yvalue, field):\n",
    "    scale = base.encode(x=\"key:N\", y=alt.value(yvalue), text=f\"min({field}):Q\")\n",
    "    return alt.layer(\n",
    "        scale.mark_text(baseline=\"middle\", align=\"right\", dx=-5, tooltip=None),\n",
    "        scale.mark_tick(size=8, color=\"#ccc\", orient=\"horizontal\", tooltip=None)\n",
    "    )\n",
    "\n",
    "alt.layer(\n",
    "    lines, rules ,ytick(0, \"max\"), ytick(150, \"mid\"), ytick(300, \"min\")\n",
    ").configure_axisX(\n",
    "    domain=False, labelAngle=0, tickColor=\"#ccc\", title=None\n",
    ").configure_view(\n",
    "    stroke=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now try a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(i):\n",
    "    if i < 1000:\n",
    "        return f\"{i}\"\n",
    "    return f\"{int(i//1000)},{int(i%1000)}\"\n",
    "\n",
    "maximum = max(vehicles[\"COLLISIONS\"])\n",
    "minimum = min(vehicles[\"COLLISIONS\"])\n",
    "mean = vehicles[\"COLLISIONS\"].mean()\n",
    "\n",
    "legend_labels = (\n",
    "    f\"datum.label == '{parse(maximum)}' ? '{parse(maximum)}   (max)' : datum.label == '{parse(minimum)}' ? '{parse(minimum)}        (min)' : '{parse(mean)}   (mean)'\"\n",
    ")\n",
    "\n",
    "\n",
    "# Using purple color as it represents the entire collision count\n",
    "scatter = alt.Chart(vehicles).mark_circle(color=colors[all_time]).encode(\n",
    "    x=alt.X(\"INJURED PER COLLISION:Q\", axis=alt.Axis(title=\"Injuries per collision\", tickCount=10)),\n",
    "    y=alt.Y(\"KILLED PER COLLISION:Q\", axis=alt.Axis(title=\"Deaths per collision\")),\n",
    "    size=alt.Size(\"COLLISIONS:Q\", scale=alt.Scale(range=[10, 700]), legend=alt.Legend(title=\"Total collisions\", values=[minimum, mean, maximum], labelExpr=legend_labels)),\n",
    ").properties(\n",
    "    width=500,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "# Lets add labels for each vehicle\n",
    "labels = scatter.mark_text(\n",
    "    align=\"right\",\n",
    "    dx=-15,\n",
    "    dy=0\n",
    ").encode(\n",
    "    text=\"VEHICLE:N\",\n",
    "    size=alt.value(10)\n",
    ")\n",
    "\n",
    "q2 = (scatter + labels).properties(\n",
    "    title=\"Vehicle Danger\",\n",
    "    width=590,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one seems to be easier to understand and also looks nicer, we have decided to keep this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(q1 & q2).configure_legend(symbolOpacity=1).resolve_scale(size=\"independent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccceb09a",
   "metadata": {},
   "source": [
    "### 3. At what time of the day are accidents more common?\n",
    "Lets make a simpler historgram with the overall average as well as a little mark indicating the max hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7931b9-ec27-4e67-aabd-73760d727cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df = collisions\n",
    "time_df[\"HOUR\"] = pd.to_datetime(time_df[\"CRASH DATETIME\"]).dt.hour\n",
    "time_df = time_df.groupby([\"HOUR\", \"AFTER COVID\"]).size().reset_index(name=\"counts\")\n",
    "\n",
    "time_df[\"MOMENT\"] = np.where(time_df[\"AFTER COVID\"], after, before)\n",
    "\n",
    "time_ch = alt.Chart(time_df).mark_bar(opacity=opacity).encode(\n",
    "    x=alt.X(\"HOUR:O\", axis=alt.Axis(labelAngle=0, tickOffset=-10), title=\"Hour\"),\n",
    "    y=alt.Y(\"counts:Q\", title=\"Collisions / Mean\"),\n",
    "    color=alt.Color(\n",
    "        \"MOMENT:O\",\n",
    "        scale=alt.Scale(domain=list(colors.keys()), range=list(colors.values())),\n",
    "        legend=alt.Legend(title=None)\n",
    "    ),\n",
    "    order=alt.Order(\"MOMENT:O\", sort=\"ascending\")\n",
    ")\n",
    "\n",
    "time_all_df = time_df.groupby([\"HOUR\"]).sum().reset_index()\n",
    "\n",
    "averages_weekend = alt.Chart(time_all_df).mark_rule(opacity=1, color=colors[all_time]).encode(\n",
    "    y=\"mean(counts):Q\",\n",
    "    size=alt.value(2),\n",
    ")\n",
    "\n",
    "max_hour = alt.Chart().mark_text(text=str(sum(time_df.loc[time_df[\"HOUR\"] == 16, \"counts\"])), angle=0).encode(\n",
    "    x=alt.value(330),\n",
    "    y=alt.value(20),\n",
    ")\n",
    "\n",
    "q3 = (time_ch + averages_weekend).properties(title=\"Collisions by Hour\")\n",
    "q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d586f5-be41-4b64-8e25-f797640275c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "((q1 | q3) & q2).configure_legend(symbolOpacity=1).resolve_scale(size=\"independent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e09726",
   "metadata": {},
   "source": [
    "### 4. Are there any areas with a larger number of accidents?\n",
    "Lets make a choropleth map. First, lets just a couple collisions in NYC. We are using a district map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c033f70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = alt.Chart(map_data).mark_geoshape(fill=\"lightgray\", stroke=\"black\").project(type=\"albersUsa\").properties(\n",
    "    width=700,\n",
    "    height=700\n",
    ")\n",
    "\n",
    "pts = alt.Chart(collisions[collisions[\"LOCATION\"].notna()].head(5000)).mark_circle().encode(\n",
    "    latitude=\"LATITUDE\",\n",
    "    longitude=\"LONGITUDE\",\n",
    "    color='BOROUGH',\n",
    "    tooltip=['LATITUDE', \"LONGITUDE\"]\n",
    ")\n",
    "\n",
    "(base + pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d44e4fe",
   "metadata": {},
   "source": [
    "Now making the Choropleth Map! We will be using the purple scale as we will be using the entire dataset, not just before/after covid. Keep in mind that we will only be looking at area, there are other factors too, like total km of streets. However, we have decided to go with this path as any other variable would be tricky to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23899598",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = alt.Chart(map_data).mark_geoshape().project(type=\"albersUsa\").encode(\n",
    "    color=alt.Color(\"COLLISIONS / KM2:Q\", scale=alt.Scale(scheme='purples'), legend=alt.Legend(title=\"Collisions per km2\")),\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=600,\n",
    "    title=\"NYC Community Districts\"\n",
    ")\n",
    "\n",
    "base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6681777",
   "metadata": {},
   "source": [
    "Lets add labels to the area with most collisions per km2 and area in position 4 as 2 and 3 will be next to #1. Only 2 as getting too many more would overcrowd the map. Getting the labels from [here](https://furmancenter.org/files/sotc/SOC2007_IndexofCommunityDistricts_000.pdf). Using the centroids of the areas to get where to place the labels. Lets see how that looks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cd76ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "top = map_data.sort_values(by=\"COLLISIONS / KM2\", ascending=False).head(4)\n",
    "top[[\"LATITUDE\", \"LONGITUDE\"]] = top[\"geometry\"].centroid.apply(lambda x: pd.Series([x.y, x.x]))\n",
    "\n",
    "# \n",
    "labels = {\n",
    "    \"boro_cd\": [\"105\", \"205\"],\n",
    "    \"LABELS\": [\"Midtown\", \"Fordham\"]\n",
    "}\n",
    "\n",
    "top = top.merge(pd.DataFrame(labels), left_on=\"boro_cd\", right_on=\"boro_cd\")\n",
    "\n",
    "text_labels = alt.Chart(top).mark_text(angle=0, dx=0, dy=0, fill=\"white\", size=9).encode(\n",
    "    longitude='LONGITUDE:Q',\n",
    "    latitude='LATITUDE:Q',\n",
    "    text='LABELS:N',\n",
    ")\n",
    "\n",
    "base + text_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0162fc",
   "metadata": {},
   "source": [
    "Midtown label is good but Fordham not too much, which is barely visible. Lets place it where it can be read correctly. And lets add a couple icons for \"interesting vehicles\"!. These icons will be wherever they collided!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3ac60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top.loc[top[\"LABELS\"] == \"Fordham\", [\"LATITUDE\", \"LONGITUDE\"]] = [40.849746, -73.89958]\n",
    "\n",
    "\n",
    "text_labels = alt.Chart(top).mark_text(angle=0, dx=0, dy=0, fill=\"white\", size=9).encode(\n",
    "    longitude=\"LONGITUDE:Q\",\n",
    "    latitude=\"LATITUDE:Q\",\n",
    "    text=\"LABELS:N\",\n",
    ")\n",
    "\n",
    "\n",
    "horse = alt.Chart(collisions[collisions[\"ORIGINAL VEHICLE\"] == \"Horse\"]).mark_text(text=\"üêé\", size=18).encode(\n",
    "    longitude=\"LONGITUDE:Q\",\n",
    "    latitude=\"LATITUDE:Q\",\n",
    ")\n",
    "\n",
    "gokart = alt.Chart(collisions[collisions[\"ORIGINAL VEHICLE\"] == \"Go kart\"]).mark_text(text=\"üèéÔ∏è\", size=18).encode(\n",
    "    longitude=\"LONGITUDE:Q\",\n",
    "    latitude=\"LATITUDE:Q\",\n",
    ")\n",
    "\n",
    "\n",
    "q4 = (base + horse + gokart + text_labels).properties(width=600, height=600)\n",
    "\n",
    "q4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020303f6",
   "metadata": {},
   "source": [
    "Great! Lets now put it all together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aff4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "((q4 | (q1 & q3)) & q2).configure_legend(symbolOpacity=1).resolve_scale(size=\"independent\", color=\"shared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.  Is there a correlation between weather conditions and accidents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read weather data\n",
    "weather = pd.read_csv(\"./processed-data/weather.csv\")\n",
    "\n",
    "weather_corr = weather.drop(columns=[\"valid\"]).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the data into a long format\n",
    "corr_long = weather_corr.stack().reset_index()\n",
    "corr_long.columns = ['x', 'y', 'value']\n",
    "\n",
    "# create the heatmap\n",
    "heatmap = alt.Chart(corr_long).mark_rect().encode(\n",
    "    x='x:O',\n",
    "    y='y:O',\n",
    "    color='value:Q'\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "# add text to the heatmap\n",
    "text = heatmap.mark_text(baseline='middle').encode(\n",
    "    text=alt.Text('value:Q', format='.2f'),\n",
    "    color=alt.condition(\n",
    "        alt.datum.value > 0.5,\n",
    "        alt.value('white'),\n",
    "        alt.value('black')\n",
    "    )\n",
    ")\n",
    "\n",
    "heatmap + text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this heatmap, we can see that there is a significant relationship between the columns `vsby` and `relh`; low visibility values are associated with high relative humidity values. There is also a strong correlation between the columns `relh` and `tmpf`. All of this makes a lot of sense when we consider the thermodynamics relation between climatic variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the columns we want to keep\n",
    "collisions_weather_selected  = collisions[['CRASH DATETIME', 'NUMBER OF PERSONS INJURED', 'NUMBER OF PERSONS KILLED', 'VEHICLE',  'tmpf', 'relh', 'sknt', 'p01i', 'vsby']]\n",
    "\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def violinPlot(dataset, column, rang):\n",
    "    color = '#7fc97fbb' if dataset.equals(weather) else '#beaed4'\n",
    "    title = 'Normal' if dataset.equals(weather) else 'Collisions'\n",
    "    orient = 'right' if dataset.equals(weather) else 'left'\n",
    "    chart = alt.Chart(dataset , width=100).transform_density(\n",
    "        column,\n",
    "        as_=[column, 'density'],\n",
    "        extent= rang\n",
    "    ).mark_area(orient='horizontal', color = color).encode(\n",
    "        alt.X('density:Q')\n",
    "            .stack('center')\n",
    "            .impute(None)\n",
    "            .title(None)\n",
    "            .axis(labels=False, values=[0], grid=False, ticks=True),\n",
    "        alt.Y(column + ':Q').title(title).axis(titleColor=color, orient=orient)\n",
    "    )\n",
    "\n",
    "    # Calculate quartiles\n",
    "    q1 = dataset[column].quantile(0.25)\n",
    "    q2 = dataset[column].quantile(0.5)\n",
    "    q3 = dataset[column].quantile(0.75)\n",
    "\n",
    "    # Add quartiles as horizontal lines\n",
    "    q1_r = alt.Chart(pd.DataFrame({'y': [q1]})).mark_rule(color='#fee0d2', strokeWidth=2).encode(y='y')\n",
    "    q2_r = alt.Chart(pd.DataFrame({'y': [q2]})).mark_rule(color='#fc9272', strokeWidth=2).encode(y='y')\n",
    "    q3_r = alt.Chart(pd.DataFrame({'y': [q3]})).mark_rule(color='#de2d26', strokeWidth=2).encode(y='y')\n",
    "\n",
    "    return chart + q1_r + q2_r + q3_r\n",
    "\n",
    "(violinPlot(collisions_weather_selected, 'tmpf', [5, 45]) | \n",
    " violinPlot(weather, 'tmpf', [5, 45])\n",
    ").properties(\n",
    "    title = \"Temperature\"\n",
    ") | (violinPlot(collisions_weather_selected, 'relh', [0, 100]) | \n",
    " violinPlot(weather, 'relh', [0, 100])\n",
    ").properties(\n",
    "    title = \"Humidity\"\n",
    ") | (violinPlot(collisions_weather_selected, 'sknt', [0, 25]) | \n",
    " violinPlot(weather, 'sknt', [0, 25])\n",
    ").properties(\n",
    "    title = \"Speed of wind\"\n",
    ") | (violinPlot(collisions_weather_selected, 'p01i', [0, 0.5]) | \n",
    " violinPlot(weather, 'p01i', [0, 0.5])\n",
    ").properties(\n",
    "    title = \"Rainfall level\"\n",
    ") | (violinPlot(collisions_weather_selected, 'vsby', [0, 20]) | \n",
    " violinPlot(weather, 'vsby', [0, 20])\n",
    ").properties(\n",
    "    title = \"Visibility\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this plot, we can compare the distribution of climatic variables when accidents occur versus their distribution at all times. The intention behind creating this graph was to help us understand if these distributions vary when accidents happen, that is, whether certain meteorological variables affect the number of accidents.\n",
    "\n",
    "In some cases, we observe slightly different distributions, but it's not easy to compare them directly in this form. We need to find another way to address the question. The idea will be to look for the most extreme cases. We'll start with visibility, where we clearly see that the first quartile is at a lower level when accidents occur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Visibility in accidents: {collisions_weather_selected['vsby'].describe()}\")\n",
    "print(f\"Visibility  in general: {weather['vsby'].describe()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this data, it can be concluded that when visibility is lower, there are more accidents, as indicated by the lower mean and the lower first quartile. The other quartiles are at a value of 16.093440 kilometers, equivalent to 10 miles, which is considered complete visibility according to the data source.\n",
    "\n",
    "However, it would be essential to study the probability of an accident with low visibility compared to the probability of an accident with high visibility.\n",
    "\n",
    "A clearer way to represent this would be the following:\n",
    "\n",
    "Histogram where the X-axis represents visibility, and the Y-axis represents the number of accidents/occurrences in weather conditions.\n",
    "This way, we can determine the collision ratio, providing more valuable information about the likelihood of accidents concerning different visibility conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 17 bins for the vsby column\n",
    "bins = pd.cut(collisions_weather_selected.dropna(subset=[\"vsby\"])[\"vsby\"], bins=17, labels=list(range(17)))\n",
    "\n",
    "# group by the bins\n",
    "grouped = collisions_weather_selected.groupby(bins)\n",
    "\n",
    "# get the count of collisions in each bin\n",
    "counts = grouped.size()\n",
    "\n",
    "\n",
    "# create 17 bins for the vsby column\n",
    "bins_weather = pd.cut(weather.dropna(subset=[\"vsby\"])['vsby'], bins=17, labels=range(17))\n",
    "\n",
    "# group by the bins\n",
    "grouped_weather = weather.groupby(bins_weather)\n",
    "\n",
    "# get the count of collisions in each bin\n",
    "counts_weather = grouped_weather.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe with counts and counts_weather\n",
    "df = pd.DataFrame({'counts': counts, 'counts_weather': counts_weather})\n",
    "\n",
    "# create a new column with the ratio of counts to counts_weather\n",
    "df['ratio'] = df['counts'] / df['counts_weather']\n",
    "\n",
    "df['visibility'] = df.index \n",
    "\n",
    "# create the bar chart\n",
    "chart = alt.Chart(df).mark_bar().encode(\n",
    "    x=alt.X('visibility:O', axis=alt.Axis(title='Visibility')),\n",
    "    y=alt.Y('ratio:Q', axis=alt.Axis(title='Ratio of Collisions')),\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "# add the mean to the plot\n",
    "mean_line = alt.Chart(df).mark_rule(color='red', strokeDash=[5,5]).encode(\n",
    "    y='mean(ratio):Q'\n",
    ")\n",
    "\n",
    "chart + mean_line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It could be beneficial for the user to understand how far each data point is from the average value. To achieve this, we will calculate the z-score for each data point, which measures the number of standard deviations a particular data point is from the mean. By plotting the data using a divergent color scheme based on the z-scores, we can emphasize the more extreme values in the dataset. This visual representation will highlight instances where the data significantly deviates from the mean, providing a clearer insight into the distribution and identifying any outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean and standard deviation of the ratio\n",
    "mean_ratio = df['ratio'].mean()\n",
    "std_ratio = df['ratio'].std()\n",
    "\n",
    "# calculate the Z-Score for each data point\n",
    "df['z_score'] = (df['ratio'] - mean_ratio) / std_ratio\n",
    "\n",
    "# create the scatter plot\n",
    "scatter = alt.Chart(df).mark_circle().encode(\n",
    "    x=alt.X('visibility:O', axis=alt.Axis(title='Visibility')),\n",
    "    y=alt.Y('z_score:Q', axis=alt.Axis(title='Z-Score of Ratio')),\n",
    "    color=alt.Color('z_score:Q', scale=alt.Scale(scheme='purplegreen')),\n",
    "    tooltip=['visibility', 'z_score']\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "# add the mean line to the plot\n",
    "mean_line = alt.Chart(df).mark_rule(color='red', strokeDash=[5,5]).encode(\n",
    "    y='mean(z_score):Q'\n",
    ")\n",
    "\n",
    "scatter + mean_line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we can do is combine the two graphs, and we have the following solutions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe with counts and counts_weather\n",
    "df = pd.DataFrame({'counts': counts, 'counts_weather': counts_weather})\n",
    "\n",
    "# create a new column with the ratio of counts to counts_weather\n",
    "df['ratio'] = df['counts'] / df['counts_weather']\n",
    "\n",
    "df['visibility'] = df.index \n",
    "\n",
    "mean_ratio = df['ratio'].mean()\n",
    "std_ratio = df['ratio'].std()\n",
    "\n",
    "df['pstd'] = mean_ratio + 2*std_ratio\n",
    "df['nstd'] = mean_ratio - 2*std_ratio\n",
    "\n",
    "# calculate the Z-Score for each data point\n",
    "df['z_score'] = (df['ratio'] - mean_ratio) / std_ratio\n",
    "\n",
    "# create the bar chart\n",
    "bar = alt.Chart(df).mark_bar().encode(\n",
    "    x=alt.X('visibility:O', axis=alt.Axis(title='Visibility')),\n",
    "    y=alt.Y('ratio:Q', axis=alt.Axis(title='Ratio of Collisions')),\n",
    "    color=alt.Color('z_score:Q', scale=alt.Scale(scheme='purplegreen'), legend = alt.Legend(title='Z-Score of Ratio'))\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "# create the bar chart\n",
    "rule = alt.Chart(df).mark_rule().encode(\n",
    "    x=alt.X('visibility:O', axis=alt.Axis(title='Visibility')),\n",
    "    y=alt.Y('ratio:Q', axis=alt.Axis(title='Ratio of Collisions')),\n",
    "    color=alt.Color('z_score:Q', scale=alt.Scale(scheme='purplegreen'), legend = None)\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "# create the bar chart\n",
    "point = alt.Chart(df).mark_circle().encode(\n",
    "    x=alt.X('visibility:O', axis=alt.Axis(title='Visibility')),\n",
    "    y=alt.Y('ratio:Q', axis=alt.Axis(title='Ratio of Collisions')),\n",
    "    color=alt.Color('z_score:O', scale=alt.Scale(scheme='purplegreen'), legend= None)\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "# add the mean to the plot\n",
    "mean_line = alt.Chart(df).mark_rule(color='gray', strokeDash=[5,5]).encode(\n",
    "    y='mean(ratio):Q'\n",
    ")\n",
    "\n",
    "pstd_line = alt.Chart(df).mark_rule(color='black', strokeDash=[5,5]).encode(\n",
    "    y='pstd:Q'\n",
    ")\n",
    "\n",
    "nstd_line = alt.Chart(df).mark_rule(color='black', strokeDash=[5,5]).encode(\n",
    "    y='nstd:Q'\n",
    ")\n",
    "\n",
    "(bar + mean_line + pstd_line + nstd_line) | (rule + point + mean_line + pstd_line + nstd_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two options, a barplot and a lollipop chart. Both represent the same information, but it seems that the barplot is easier to read. Therefore, we will stick with this graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot indicates a noticeable trend: as visibility decreases, the likelihood of an accident appears to increase. This observation is supported by the analysis of Z-Scores, which suggests that instances of extremely low visibility, represented by points around 1.5 standard deviations below the mean, are associated with a higher probability of accidents. In simpler terms, when visibility is severely reduced, the data suggests a greater chance of accidents occurring. This aligns with the common understanding that adverse weather conditions leading to poor visibility can contribute to an elevated risk of accidents.\n",
    "\n",
    "\n",
    "Still, a doubt arises: why are the results less conclusive than expected? This is because visibility is closely related to humidity, and humidity, in turn, is related to temperature, which is highly influenced by the time of day. Therefore, we can imagine that the hours with lower visibility coincide with the hours when there are fewer accidents. This is something we will verify shortly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the hour from the DATE column\n",
    "collisions_weather_selected['HOUR'] = pd.to_datetime(collisions_weather_selected['CRASH DATETIME']).dt.hour\n",
    "\n",
    "# group by hour and calculate the mean of the visibility column\n",
    "mean_visibility = collisions_weather_selected.groupby('HOUR')['vsby'].mean()\n",
    "\n",
    "\n",
    "# create a chart with the mean visibility by hour\n",
    "visby_hour = alt.Chart(mean_visibility.reset_index()).mark_bar().encode(\n",
    "    x=alt.X('HOUR:O', axis=alt.Axis(title='Hour')),\n",
    "    y=alt.Y('vsby:Q', axis=alt.Axis(title='Mean Visibility')),\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "# add the mean line\n",
    "mean_line = alt.Chart(mean_visibility.reset_index()).mark_rule(color='red', strokeDash=[5,5]).encode(\n",
    "    y='mean(vsby):Q'\n",
    ")\n",
    "\n",
    "visby_hour + mean_line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that between 6 and 7 a.m. are the hours with the least visibility, coinciding with hours with fewer collisions. This is not a causal relationship, meaning that lower visibility doesn't directly cause fewer accidents; that wouldn't make sense. Instead, the hours with lower visibility align with times when fewer people are driving, and therefore, there are fewer accidents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column with the visibility category\n",
    "collisions_weather_selected['VISIBILITY CATEGORY'] = np.where(collisions_weather_selected['vsby'] > 16, 'High Visibility', 'Low Visibility')\n",
    "\n",
    "# group by hour and visibility category and calculate the count of collisions\n",
    "hourly_visibility = collisions_weather_selected.groupby(['HOUR', 'VISIBILITY CATEGORY']).size().reset_index(name='counts')\n",
    "\n",
    "\n",
    "# calculate the total number of collisions per hour\n",
    "hourly_total = hourly_visibility.groupby('HOUR')['counts'].sum().reset_index(name='total')\n",
    "\n",
    "# merge the hourly_visibility and hourly_total dataframes\n",
    "hourly_visibility = pd.merge(hourly_visibility, hourly_total, on='HOUR')\n",
    "\n",
    "# calculate the percentage of low and high visibility collisions\n",
    "hourly_visibility['percentage'] = hourly_visibility['counts'] / hourly_visibility['total'] * 100\n",
    "\n",
    "# create the stacked bar chart\n",
    "stacked_bar = alt.Chart(hourly_visibility).mark_bar().encode(\n",
    "    x=alt.X('HOUR:O', axis=alt.Axis(title='Hour')),\n",
    "    y=alt.Y('percentage:Q', axis=alt.Axis(title='Percentage of Collisions')),\n",
    "    color=alt.Color('VISIBILITY CATEGORY:N', scale=alt.Scale(domain=['Low Visibility', 'High Visibility'], range=['#1f77b4', '#ff7f0e']), legend=alt.Legend(title='Visibility Category'))\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "stacked_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will proceed with a similar approach, but without categorizing data into bins. Instead, we'll thoroughly analyze all the ratios, exploring the dataset to identify any discernible trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_weather(collisions_weather_selected, weather, column_name, grafic):\n",
    "    \"\"\"\n",
    "    Generate a scatter plot with a regression line to visualize relationships between weather data and collision statistics.\n",
    "\n",
    "    Parameters:\n",
    "    - collisions_weather_selected (pd.DataFrame): DataFrame containing collision data with weather information.\n",
    "    - weather (pd.DataFrame): DataFrame containing weather information.\n",
    "    - column_name (str): The column in the dataframes to analyze and compare.\n",
    "    - grafic (str): The type of relationship to visualize (\"COLLISIONS PER HOUR\", \"INJURED PER ACCIDENT\", or \"KILLED PER ACCIDENT\").\n",
    "\n",
    "    Returns:\n",
    "    alt.Chart: An Altair chart displaying the scatter plot and a regression line.\n",
    "    \"\"\"\n",
    "\n",
    "    # Data Preparation\n",
    "    df = collisions_weather_selected.groupby(column_name).agg({\n",
    "        column_name: \"count\",\n",
    "        \"NUMBER OF PERSONS INJURED\": \"sum\",\n",
    "        \"NUMBER OF PERSONS KILLED\": \"sum\"\n",
    "    }).rename(columns={column_name: \"count\"}).reset_index()\n",
    "\n",
    "    ocurrance = weather.groupby(column_name).size().reset_index(name=\"ocurrance\")\n",
    "\n",
    "    df = df.merge(ocurrance, on=column_name)\n",
    "\n",
    "    # Calculate additional metrics based on user choice\n",
    "    if grafic == \"COLLISIONS PER HOUR\":\n",
    "        df[\"COLLISIONS PER HOUR\"] = df[\"count\"] / df[\"ocurrance\"]\n",
    "    elif grafic == \"INJURED PER ACCIDENT\":\n",
    "        df[\"INJURED PER ACCIDENT\"] = df[\"NUMBER OF PERSONS INJURED\"] / df[\"count\"]\n",
    "    elif grafic == \"KILLED PER ACCIDENT\":\n",
    "        df[\"KILLED PER ACCIDENT\"] = df[\"NUMBER OF PERSONS KILLED\"] / df[\"count\"]\n",
    "\n",
    "    # Calculate statistics for size legend\n",
    "    minimum = min(df[\"ocurrance\"])\n",
    "    maximum = max(df[\"ocurrance\"])\n",
    "    mean = df[\"ocurrance\"].mean()\n",
    "\n",
    "    # Create scatter plot with optional regression line\n",
    "    scatterplot = alt.Chart(df).mark_circle().encode(\n",
    "        x=column_name + \":Q\",\n",
    "        y=grafic + \":Q\",\n",
    "        size=alt.Size(\"ocurrance:Q\", scale=alt.Scale(range=[10, 700]), legend=alt.Legend(title=\"Occurrences\", values=[minimum, mean, maximum])),\n",
    "    ).properties(\n",
    "        width=400,\n",
    "        height=300\n",
    "    )\n",
    "\n",
    "    regression = scatterplot.transform_regression(\n",
    "        column_name, grafic, method=\"linear\"\n",
    "    ).mark_line(color=\"red\")\n",
    "\n",
    "    # Combine and return the chart\n",
    "    return (scatterplot + regression).resolve_scale(y='shared')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charts = [\"COLLISIONS PER HOUR\", \"INJURED PER ACCIDENT\", \"KILLED PER ACCIDENT\"]\n",
    "variables = [\"vsby\", \"tmpf\", \"sknt\", \"p01i\"]\n",
    "\n",
    "show_charts = []\n",
    "for grafic in charts:\n",
    "    for variable in variables:\n",
    "        show_charts.append(visualize_weather(collisions_weather_selected, weather, variable, grafic))\n",
    "\n",
    "\n",
    "(((show_charts[0] | show_charts[1] | show_charts[2] | show_charts[3]) &\n",
    "(show_charts[4] | show_charts[5] | show_charts[6] | show_charts[7])) &\n",
    "(show_charts[8] | show_charts[9] | show_charts[10] | show_charts[11]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't seem like we can reach a conclusive answer, as the distributions don't provide sufficient information. Other modifications that occurred to us to enhance this graph were:\n",
    "\n",
    "- Adding the Pearson and Spearman correlation coefficients.\n",
    "\n",
    "- Introducing color-coding based on the year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we won't pursue this path further and will continue exploring with the barplot we had. Other potential avenues could have included:\n",
    "\n",
    "- Conducting hypothesis tests to compare the means of meteorological variables on days with accidents and without accidents.\n",
    "\n",
    "- Employing clustering algorithms to group days with similar meteorological conditions and analyzing the accident frequency in each cluster.\n",
    "\n",
    "- Segmenting the data by hours of the day and examining if there are significant differences in meteorological conditions between hours with more accidents and hours with fewer accidents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rainfall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now follow the same process for rainfall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# select the rows where p01i is 0\n",
    "zero_p01i = collisions_weather_selected.loc[collisions_weather_selected['p01i'] == 0]\n",
    "\n",
    "# get the number of rows with p01i = 0\n",
    "num_zero_p01i = len(zero_p01i)\n",
    "\n",
    "# select the rows where p01i is not 0\n",
    "nonzero_p01i = collisions_weather_selected.loc[collisions_weather_selected['p01i'] != 0]\n",
    "\n",
    "# create 10 bins for the p01i column\n",
    "bins = pd.cut(nonzero_p01i.dropna(subset=[\"p01i\"])['p01i'], bins=10)\n",
    "\n",
    "# get the midpoint of each interval\n",
    "midpoints = bins.apply(lambda x: x.mid.round(2))\n",
    "\n",
    "# group by the midpoints\n",
    "grouped = nonzero_p01i.groupby(midpoints)\n",
    "\n",
    "# convert the result of the groupby to a dataframe\n",
    "grouped_df = grouped.size().reset_index(name='counts')\n",
    "\n",
    "# create a new dataframe with the count of rows with p01i = 0\n",
    "zero_row = pd.DataFrame({'p01i': [0], 'counts': [num_zero_p01i]})\n",
    "\n",
    "counts = pd.concat([zero_row , grouped_df])\n",
    "\n",
    "# select the rows where p01i is 0\n",
    "zero_p01i_weather = weather.loc[weather['p01i'] == 0]\n",
    "\n",
    "# get the number of rows with p01i = 0\n",
    "num_zero_p01i_weather = len(zero_p01i_weather)\n",
    "\n",
    "# select the rows where p01i is not 0\n",
    "nonzero_p01i_weather = weather.loc[weather['p01i'] != 0]\n",
    "\n",
    "# create 10 bins for the p01i column\n",
    "bins_weather = pd.cut(nonzero_p01i_weather.dropna(subset=[\"p01i\"])['p01i'], bins=10)\n",
    "\n",
    "# get the midpoint of each interval\n",
    "midpoints_weather = bins_weather.apply(lambda x: x.mid.round(2))\n",
    "\n",
    "# group by the midpoints\n",
    "grouped_weather = nonzero_p01i_weather.groupby(midpoints_weather)\n",
    "\n",
    "# convert the result of the groupby to a dataframe\n",
    "grouped_df_weather = grouped_weather.size().reset_index(name='counts')\n",
    "\n",
    "# create a new dataframe with the count of rows with p01i = 0\n",
    "zero_row_weather = pd.DataFrame({'p01i': [0], 'counts': [num_zero_p01i_weather]})\n",
    "\n",
    "counts_weather= pd.concat([zero_row_weather, grouped_df_weather])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe with counts and counts_weather\n",
    "df = pd.DataFrame({'p01i': counts['p01i'] ,'counts': counts['counts'], 'counts_weather': counts_weather['counts']})\n",
    "\n",
    "# create a new column with the ratio of counts to counts_weather\n",
    "df['ratio'] = df['counts'] / df['counts_weather']\n",
    "\n",
    "mean_ratio = df['ratio'].mean()\n",
    "std_ratio = df['ratio'].std()\n",
    "\n",
    "df['mean'] = mean_ratio\n",
    "df['pstd'] = mean_ratio + 2*std_ratio\n",
    "df['nstd'] = mean_ratio - 2*std_ratio\n",
    "\n",
    "# calculate the Z-Score for each data point\n",
    "df['z_score'] = (df['ratio'] - mean_ratio) / std_ratio\n",
    "\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# create the bar chart\n",
    "bar = alt.Chart(df).mark_bar().encode(\n",
    "    x=alt.X('p01i:O', axis=alt.Axis(title='Rain level')),\n",
    "    y=alt.Y('ratio:Q', axis=alt.Axis(title='Ratio of Collisions')),\n",
    "    color=alt.Color('z_score:Q', scale=alt.Scale(scheme='purplegreen'), legend = alt.Legend(title='Z-Score of Ratio'))\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "# add the mean to the plot\n",
    "mean_line = alt.Chart(df).mark_rule(color='gray', strokeDash=[5,5]).encode(\n",
    "    y='mean:Q'\n",
    ")\n",
    "\n",
    "pstd_line = alt.Chart(df).mark_rule(color='black', strokeDash=[5,5]).encode(\n",
    "    y='pstd:Q'\n",
    ")\n",
    "\n",
    "nstd_line = alt.Chart(df).mark_rule(color='black', strokeDash=[5,5]).encode(\n",
    "    y='nstd:Q'\n",
    ")\n",
    "\n",
    "(bar + mean_line + pstd_line + nstd_line) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result we might expect is that the collision ratio increases as the rainfall level rises, and this is true up to values of 2.69 cm of rainfall. Except for the bar at 2.28, as it seems to be an outlier, indicating only one occurrence of rain in that interval. It is also surprising that the ratio decreases for 3.93, but again, this is an outlier that has only occurred once. As a solution, we could consider creating the following plot: raining vs. not raining."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the graph we want to display will be the combination of two plots: the previous barplot and now a binary barplot indicating collisions per hour during rainfall and non-rainfall conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather_chart(collisions_weather_selected, weather, column_name, value, nbins):\n",
    "    \"\"\"\n",
    "    Generate and visualize a bar chart comparing the collisions per hour in different weather conditions.\n",
    "\n",
    "    Parameters:\n",
    "    - collisions_weather_selected (pd.DataFrame): DataFrame containing collision data with weather information.\n",
    "    - weather (pd.DataFrame): DataFrame containing weather information.\n",
    "    - column_name (str): The column in the dataframes to analyze and compare.\n",
    "    - value (float): The specific value within the column to focus on for comparison. This value will be the most common value for each column. For example, for rainfall, it \n",
    "      will be 0, but for visibility, it will be 16.093440.\n",
    "    - nbins (int): Number of bins to use for grouping non-zero values. This will be used to group the data into bins of equal width. But there will be an exception; a \n",
    "      barplot will be created for the value of 'value,' so there will actually be nbins + 1 bins.\n",
    "\n",
    "    Returns:\n",
    "    alt.Chart: An Altair chart displaying the collisions per hour in different weather conditions, along with statistical indicators.\n",
    "    \"\"\"\n",
    "\n",
    "    # Data Processing (for collisions)\n",
    "    zero = collisions_weather_selected.loc[collisions_weather_selected[column_name] == value]\n",
    "    num_zero = len(zero)\n",
    "\n",
    "    nonzero = collisions_weather_selected.loc[collisions_weather_selected[column_name] != value]\n",
    "    num_nonzero = len(nonzero)\n",
    "\n",
    "    bins = pd.cut(nonzero.dropna(subset=[column_name])[column_name], bins=nbins)\n",
    "    midpoints = bins.apply(lambda x: x.mid.round(2))\n",
    "\n",
    "    grouped = nonzero.groupby(midpoints)\n",
    "    grouped_df = grouped.size().reset_index(name='counts')\n",
    "\n",
    "    zero_row = pd.DataFrame({column_name: [value], 'counts': [num_zero]})\n",
    "    non_zero_row = pd.DataFrame({column_name: [1], 'counts': [num_nonzero]})\n",
    "\n",
    "    counts = pd.concat([zero_row , grouped_df])\n",
    "\n",
    "    # Data Processing (for weather)\n",
    "    zero_weather = weather.loc[weather[column_name] == value]\n",
    "    num_zero_weather = len(zero_weather)\n",
    "\n",
    "    nonzero_weather = weather.loc[weather[column_name] != value]\n",
    "    num_nonzero_weather = len(nonzero_weather)\n",
    "\n",
    "    bins_weather = pd.cut(nonzero_weather.dropna(subset=[column_name])[column_name], bins=nbins)\n",
    "    midpoints_weather = bins_weather.apply(lambda x: x.mid.round(2))\n",
    "\n",
    "    grouped_weather = nonzero_weather.groupby(midpoints_weather)\n",
    "    grouped_df_weather = grouped_weather.size().reset_index(name='counts')\n",
    "\n",
    "    zero_row_weather = pd.DataFrame({column_name: [value], 'counts': [num_zero_weather]})\n",
    "    non_zero_row_weather = pd.DataFrame({column_name: [1], 'counts': [num_nonzero_weather]})\n",
    "\n",
    "    counts_weather = pd.concat([zero_row_weather, grouped_df_weather])\n",
    "\n",
    "    # Combine Collision and Weather Data\n",
    "    df = pd.DataFrame({column_name: counts[column_name] ,'counts': counts['counts'], 'counts_weather': counts_weather['counts']})\n",
    "\n",
    "    # Data Processing (for statistical analysis)\n",
    "    counts_bin = pd.concat([zero_row , non_zero_row])\n",
    "    counts_weather_bin = pd.concat([zero_row_weather , non_zero_row_weather])\n",
    "    df_bin = pd.DataFrame({column_name: counts_bin[column_name] ,'counts': counts_bin['counts'], 'counts_weather': counts_weather_bin['counts']})\n",
    "\n",
    "    df['ratio'] = df['counts'] / df['counts_weather']\n",
    "\n",
    "    mean_ratio = df['ratio'].mean()\n",
    "    std_ratio = df['ratio'].std()\n",
    "\n",
    "    df['mean'] = mean_ratio\n",
    "    df['pstd'] = mean_ratio + 2 * std_ratio\n",
    "    df['nstd'] = mean_ratio - 2 * std_ratio\n",
    "\n",
    "    # Calculate the Z-Score for each data point\n",
    "    df['z_score'] = (df['ratio'] - mean_ratio) / std_ratio\n",
    "\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "    # Visualization (for Ratio of Collisions)\n",
    "    bar = alt.Chart(df).mark_bar().encode(\n",
    "        x=alt.X(column_name + ':O'),\n",
    "        y=alt.Y('ratio:Q', axis=alt.Axis(title='Collisions per Hour')),\n",
    "        color=alt.Color('z_score:Q', scale=alt.Scale(scheme='brownbluegreen'), legend = alt.Legend(title='Z-Score of Ratio'))\n",
    "    ).properties(\n",
    "        width=400,\n",
    "        height=300\n",
    "    )\n",
    "\n",
    "    # Add statistical indicators to the plot\n",
    "    mean_line = alt.Chart(df).mark_rule(color='gray', strokeDash=[5,5]).encode(\n",
    "        y='mean:Q'\n",
    "    )\n",
    "\n",
    "    pstd_line = alt.Chart(df).mark_rule(color='black', strokeDash=[5,5]).encode(\n",
    "        y='pstd:Q'\n",
    "    )\n",
    "\n",
    "    nstd_line = alt.Chart(df).mark_rule(color='black', strokeDash=[5,5]).encode(\n",
    "        y='nstd:Q'\n",
    "    )\n",
    "\n",
    "    # Additional Visualization (Binary Bar Chart)\n",
    "    df_bin['ratio'] = df_bin['counts'] / df_bin['counts_weather']\n",
    "\n",
    "    binary_bar = alt.Chart(df_bin).mark_bar(size=90).encode(\n",
    "        x=alt.X(column_name + \":O\"),\n",
    "        y=alt.Y('ratio:Q', axis=alt.Axis(title=None, labels=False, domain=False, ticks=False, grid=True)),\n",
    "    ).properties(\n",
    "        width=200,\n",
    "        height=300\n",
    "    )\n",
    "\n",
    "    # Combine and Return\n",
    "    return ((bar + mean_line + pstd_line + nstd_line) | binary_bar).resolve_scale(y='shared')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_chart(collisions_weather_selected, weather, 'p01i', 0, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now adjusted the color scale to avoid using colors previously employed in other graphs. Additionally, we have added the binary histogram. Furthermore, we have reduced the number of bins since we observed that instances of extreme meteorological conditions are infrequent, resulting in a limited number of records. By reducing the number of bins, we aim to strengthen the conclusions drawn from the data. Additionally, we have modified the name of the Y-axis to 'Collisions per Hour' for greater clarity and self-explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have created a function to generate this type of graph, we can now produce this plot for any meteorological variable of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_chart(collisions_weather_selected, weather, 'sknt', 0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_chart(collisions_weather_selected, weather, 'vsby', 16.093440, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these graphs, we realize that perhaps we no longer need the binary plot. Furthermore, we have reimagined the entire approach. We now have barplots to address questions 1 and 3. Moreover, the color in these graphs simply shows the distance from the mean value. It may not be providing as much information relative to the space they occupy. That's why, in the end, we have opted to represent it in a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_column_count_df(collisions_weather_selected, weather, column_name, value, nbins):\n",
    "    \"\"\"\n",
    "    Create a DataFrame with counts and ratios based on specified conditions in the input dataframes.\n",
    "\n",
    "    Parameters:\n",
    "    - collisions_weather_selected (pd.DataFrame): DataFrame containing collision data with weather information.\n",
    "    - weather (pd.DataFrame): DataFrame containing weather information.\n",
    "    - column_name (str): The column in the dataframes to analyze and compare.\n",
    "    - value (float): The specific value within the column to focus on for comparison.\n",
    "    - nbins (int): Number of bins to use for grouping non-zero values.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing the specified column, counts, and the ratio of counts in different conditions.\n",
    "    \"\"\"\n",
    "\n",
    "    # Data Preparation (for collisions)\n",
    "    zero = collisions_weather_selected.loc[collisions_weather_selected[column_name] == value]\n",
    "    num_zero = len(zero)\n",
    "\n",
    "    nonzero = collisions_weather_selected.loc[collisions_weather_selected[column_name] != value]\n",
    "    num_nonzero = len(nonzero)\n",
    "\n",
    "    bins = pd.cut(nonzero.dropna(subset=[column_name])[column_name], bins=nbins)\n",
    "    midpoints = bins.apply(lambda x: x.mid.round(2))\n",
    "\n",
    "    grouped = nonzero.groupby(midpoints)\n",
    "    grouped_df = grouped.size().reset_index(name='counts')\n",
    "\n",
    "    zero_row = pd.DataFrame({column_name: [value], 'counts': [num_zero]})\n",
    "    counts = pd.concat([zero_row , grouped_df])\n",
    "    # Data Preparation (for weather)\n",
    "    zero_weather = weather.loc[weather[column_name] == value]\n",
    "    num_zero_weather = len(zero_weather)\n",
    "\n",
    "    nonzero_weather = weather.loc[weather[column_name] != value]\n",
    "    num_nonzero_weather = len(nonzero_weather)\n",
    "\n",
    "    bins_weather = pd.cut(nonzero_weather.dropna(subset=[column_name])[column_name], bins=nbins)\n",
    "    midpoints_weather = bins_weather.apply(lambda x: x.mid.round(2))\n",
    "\n",
    "    grouped_weather = nonzero_weather.groupby(midpoints_weather)\n",
    "    grouped_df_weather = grouped_weather.size().reset_index(name='counts')\n",
    "\n",
    "    zero_row_weather = pd.DataFrame({column_name: [value], 'counts': [num_zero_weather]})\n",
    "    counts_weather = pd.concat([zero_row_weather, grouped_df_weather])\n",
    "\n",
    "    # Combine Collision and Weather Data\n",
    "    df = pd.DataFrame({column_name: counts[column_name],\n",
    "                       'counts_' + column_name: counts['counts'],\n",
    "                       'counts_weather_' + column_name: counts_weather['counts']})\n",
    "\n",
    "    # Calculate and add ratio to the DataFrame\n",
    "    df['ratio_' + column_name] = df['counts_' + column_name] / df['counts_weather_' + column_name]\n",
    "\n",
    "    return df[[column_name, 'ratio_' + column_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 3\n",
    "df1 = create_column_count_df(collisions_weather_selected, weather, 'p01i', 0, bins).reset_index(drop=True)\n",
    "df2 = create_column_count_df(collisions_weather_selected, weather, 'sknt', 0, bins).reset_index(drop=True)\n",
    "df3 = create_column_count_df(collisions_weather_selected, weather, 'vsby', 16.093440, bins)\n",
    "\n",
    "df3_0 = df3[df3['vsby'] == 16.09344]\n",
    "df3_1 = df3[df3['vsby'] != 16.09344]\n",
    "df3_2 = pd.concat([df3_1, df3_0], axis=0).reset_index(drop=True).sort_index(ascending=False).reset_index(drop=True)\n",
    "\n",
    "heatmap_df = pd.concat([df1, df2, df3_2], axis=1)\n",
    "\n",
    "heatmap_df1 = heatmap_df.melt(id_vars=['ratio_p01i'], value_vars=['p01i'], var_name='Column', value_name='Value')\n",
    "heatmap_df1.rename(columns={'ratio_p01i': 'Ratio'}, inplace=True)\n",
    "heatmap_df2 = heatmap_df.melt(id_vars=['ratio_sknt'], value_vars=['sknt'], var_name='Column', value_name='Value')\n",
    "heatmap_df2.rename(columns={'ratio_sknt': 'Ratio'}, inplace=True)\n",
    "heatmap_df3 = heatmap_df.melt(id_vars=['ratio_vsby'], value_vars=['vsby'], var_name='Column', value_name='Value')\n",
    "heatmap_df3.rename(columns={'ratio_vsby': 'Ratio'}, inplace=True)\n",
    "\n",
    "heatmap_df = pd.concat([heatmap_df1, heatmap_df2, heatmap_df3], axis=0)\n",
    "\n",
    "heatmap_df.reset_index(inplace=True)\n",
    "\n",
    "conditionorder = [\"Perfect\", \"Moderate\", \"Bad\", \"Terrible\"]\n",
    "heatmap_df[\"CONDITION\"] = conditionorder*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axis_y_labels = (\n",
    "    \"datum.label == 'p01i' ? 'Rain' : datum.label == 'sknt' ? 'Wind' : 'Visbility'\"\n",
    ")\n",
    "\n",
    "q5 = alt.Chart(heatmap_df).mark_rect().encode(\n",
    "    x=alt.X('CONDITION:O', axis = alt.Axis(title=\"Condition\", labels=True, labelAngle=0, domain=True, ticks=True, grid=False), sort=conditionorder),\n",
    "    y=alt.Y('Column:O', axis=alt.Axis(title=\"Weather\", labelExpr=axis_y_labels)),\n",
    "    color=alt.Color('Ratio:Q', scale=alt.Scale(scheme='purples'), legend=alt.Legend(title=\"Collisions per Hour\")),\n",
    ").properties(\n",
    "    title=\"Different Weather Conditions\",\n",
    "    width=481,\n",
    "    height=300\n",
    ").resolve_legend(color=\"independent\")\n",
    "\n",
    "q5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have mapped the best conditions possible to Perfect. And the remaining 3 bins have been labelled for better to worse. Now, it is easy to see that as weather conditions worsen, the number of collisions per hour also increases. Therefore, we can address question 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((q4 | (q1 & q3)) & (q2 | q5).resolve_scale(color=\"independent\").resolve_legend(size=\"independent\")).configure_legend(symbolOpacity=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be our final visualization! Note that we mainly used purple as this color represents the entire data we have, while yellow represents before Covid and Green after Covid (get it? VIRUS!). We have also carfeully sized all plots so that they are perfectly aligned.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. What is the main cause of accidents?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Studying the different columns we have and the questions we have already answered, it seemed necessary to determine the main cause of accidents. Our initial idea is to create a heatmap where the Y-axis represents vehicle types, the X-axis represents the cause of accidents, and the color indicates the percentage of accidents for each type of vehicle. Using absolute numbers would be challenging for comparison since we know that there are many more car accidents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_df = collisions[[\"VEHICLE\", \"FACTOR\", \"ORIGINAL FACTOR\"]]\n",
    "\n",
    "# count the number of accidents for each vehicle\n",
    "factor_df_grouped_vehicle = factor_df.groupby([\"VEHICLE\"]).size().reset_index(name=\"counts_vehicle\")\n",
    "\n",
    "# count the number of accidents for each factor and for each vehicle\n",
    "factor_df_grouped = factor_df.groupby([\"VEHICLE\", \"FACTOR\"]).size().reset_index(name=\"counts\")\n",
    "\n",
    "# Drop rows with \"Unknown\" vehicle and \"Unspecified\" factor\n",
    "factor_df_grouped = factor_df_grouped[(factor_df_grouped[\"VEHICLE\"] != \"Unknown\") & (factor_df_grouped[\"FACTOR\"] != \"Unspecified\")]\n",
    "\n",
    "# merge the two dataframes\n",
    "factor_contribution_df = factor_df_grouped.merge(factor_df_grouped_vehicle, on=\"VEHICLE\")\n",
    "\n",
    "# calculate the percentage of accidents for each factor and for each vehicle\n",
    "factor_contribution_df[\"PERCENTAGE\"] = factor_contribution_df[\"counts\"] / factor_contribution_df[\"counts_vehicle\"] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_heatmap = alt.Chart(factor_contribution_df).mark_rect().encode(\n",
    "    x=alt.X(\"FACTOR:O\", axis = alt.Axis(title=\"Factor\", labelAngle=30)),\n",
    "    y=alt.Y(\"VEHICLE:O\", axis=alt.Axis(title=\"Vehicle\")),\n",
    "    color=alt.Color(\"PERCENTAGE:Q\", scale=alt.Scale(scheme=\"tealblues\"), legend=alt.Legend(title=\"Percentage of Collisions\")),\n",
    ").properties(\n",
    "    title=\"Factors Contributing to Accidents\",\n",
    "    width=522,\n",
    "    height=300\n",
    ").resolve_legend(color=\"independent\")\n",
    "\n",
    "factor_heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are two factors contributing more than others: 'Driver Inattention' and 'Driving Infraction.' It's challenging to discern much from the other factors. Therefore, we have decided to explore what happens within the original factors classified as 'Driver Inattention' and 'Driving Infraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe where FACTOR is \"Driving Infraction\"\n",
    "driving_infraction_df = factor_df[factor_df[\"FACTOR\"] == \"Driving Infraction\"]\n",
    "\n",
    "# count the number of accidents for each vehicle\n",
    "factor_df_grouped_vehicle = driving_infraction_df.groupby([\"VEHICLE\"]).size().reset_index(name=\"counts_vehicle\")\n",
    "\n",
    "# count the number of accidents for each factor and for each vehicle\n",
    "factor_df_grouped = driving_infraction_df.groupby([\"VEHICLE\", \"ORIGINAL FACTOR\"]).size().reset_index(name=\"counts\")\n",
    "\n",
    "# Drop rows with \"Unknown\" vehicle and \"Unspecified\" factor\n",
    "factor_df_grouped = factor_df_grouped[(factor_df_grouped[\"VEHICLE\"] != \"Unknown\")]\n",
    "\n",
    "# merge the two dataframes\n",
    "factor_contribution_df = factor_df_grouped.merge(factor_df_grouped_vehicle, on=\"VEHICLE\")\n",
    "\n",
    "# calculate the percentage of accidents for each factor and for each vehicle\n",
    "factor_contribution_df[\"PERCENTAGE\"] = factor_contribution_df[\"counts\"] / factor_contribution_df[\"counts_vehicle\"] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_heatmap2 = alt.Chart(factor_contribution_df).mark_rect().encode(\n",
    "    x=alt.X(\"ORIGINAL FACTOR:O\",  axis = alt.Axis(labelAngle=30, title=\"Factor\")),\n",
    "    y=alt.Y(\"VEHICLE:O\", axis=alt.Axis(title=None)),\n",
    "    color=alt.Color(\"PERCENTAGE:Q\", scale=alt.Scale(scheme=\"tealblues\"), legend=alt.Legend(title=[\"Percentage of Collisions due\", \"to Driving Infractions\"])),\n",
    ").properties(\n",
    "    title=\"Driving Infractions contributing to Accidents\",\n",
    "    width=522,\n",
    "    height=300\n",
    ").resolve_legend(color=\"independent\")\n",
    "\n",
    "factors = (factor_heatmap | factor_heatmap2).resolve_legend(color=\"independent\")\n",
    "factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    (\n",
    "        (\n",
    "            (q4 & q2)\n",
    "            .resolve_scale(color=\"independent\")\n",
    "            .resolve_legend(size=\"independent\")\n",
    "            | (q5 & (q1 & q3))\n",
    "        )\n",
    "        & factors\n",
    "    )\n",
    "    .resolve_legend(size=\"independent\")\n",
    "    .resolve_scale(color=\"independent\")\n",
    "    .configure_legend(symbolOpacity=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Questions: \n",
    "\n",
    "**1. Are accidents more frequent during weekdays or weekends? Is there any difference between before COVID-19 and after?**\n",
    "\n",
    "Looking at the 2nd chart on the right (paired bar chart), we can use the mean lines to compare overall if accidents are more frequent in weekends or in weekdays. We can expect there to be the same amount of amount of days for each days of the week (give or take one), which is why we can use the total sum of collisions. Indeed, we can use the means of weekdays (before *yellow/orange* and after *green* Covid) and the means of weekends and it is clearly higher on weekdays. We see that after Covid the total collisions are more equally distributed among the days of the week. The weekdays average is still higher than on weekends but not as pronounced.\n",
    "\n",
    "Using this chart we can also see that Fridays are the days with the most collisions (likely everyone is rushing for the weekend or simply tired from the long week) on the other hand, Sundays are the days with the least collisions.\n",
    "\n",
    "**2. Is there any type of vehicle more prone to participate in accidents?**\n",
    "\n",
    "This question is very tricky. We would need to know (per vehicle) the amount of kilometers driven for the dates we have used, to get a good representation of this question. This is because cars are for sure the vehicle with the most collisions, simply because they are driven the most km. We tried our best to find data, spent several hours in fact, but it was either incomplete or simply wrong.\n",
    "\n",
    "The 2nd chart on the left (Vehicle Danger) has Deaths per collision in the y-axis and Injuries per collision in the x-axis and total collisions for size. We can see that cars have a total of 95263 collisions (they are the largest circle), representing around 90% of the collisions. This however does not imply that cars are are 90% more prone!\n",
    "\n",
    "**3. At what time of the day are accidents more common?**\n",
    "\n",
    "Using the third chart on the right (stacked bar chart) we can see that we have the most accidents from 16 to 17. Again, since hours are equally distributed throughout the day, we can use the total amount to indicate when accidents are more common.\n",
    "\n",
    "Interesting to see the second highest maximum from 9 to 10. This latter peak corresponds with the beggining of the day and the former (16-17) with the end (when people go back home). Most collisions are concentrated from 8 to 20 (these are all over the mean).\n",
    "\n",
    "Interestingly, from 0(12)-1 we have quite a large peak that does not seem to follow the trend. This is likely due to data missing the time variable and being set at 00:00. This is not an oversight by us as we checked, and the Time variable in the original dataset has 0 nulls.\n",
    "\n",
    "**4. Are there any areas with a larger number of accidents?**\n",
    "\n",
    "Using the map on the top left (opacity represents collisions per $km^2$) we can see that the Midtown Manhattan area as well as Fordham (Bronx) are the places with most collisions per $km^2$. Labels are placed in the district with most collisions per $km^2$ and the fourth most (because of space).\n",
    "\n",
    "Using the map we can also see that a Horse crashed in Manhattan as well as a Go Kart in the Bronx! They are the sole cases of their respective vehicle type.\n",
    "\n",
    "**5. Is there a correlation between weather conditions and accidents?**\n",
    "\n",
    "Using the purple heatmap on the right, we can see that as Rain, Wind and Visibility conditons worsen, we find more collisions per hour. We see a trend with darker colors when conditions are not perfect. For Rain and Visibility, we see that for terrible conditions we have a lower collision rate, we can explain this by thinking about how a human works. With heavy heavy rain we will realise easier that we must drive safer, with a light rain we may not even care. Same goes for Visibility. Wind on the other hand is different, as once we get into the car, noticing it is harder so we don't change how we drive as much.\n",
    "\n",
    "In summary, there is a correlation, we find more accidents when conditions are not perfect.\n",
    "\n",
    "## Extra\n",
    "\n",
    "**6. What vehicles are the most dangerous?**\n",
    "\n",
    "Using the 2nd chart on the left scatter plot, we can see that two-wheelers injure more people per collision than four-wheelers! These latter vehicles have a chasis that protect the people inside in a collision, however, two-wheelers do not. If we look a bit closer, we see that the faster a two-wheeler is, the higher death rate! With motorcycle being the vehicle with most deaths per collision.\n",
    "\n",
    "**7. What is the main cause of accidents?**\n",
    "\n",
    "Using the left heatmap in the blue-teal pair at the bottom, it becomes evident that the primary causes of accidents are driving infractions and driver inattention. However, delving deeper into the chart reveals additional valuable insights. Notably, in the case of bicycles and e-bikes, accidents caused by pedestrian errors are more likely compared to other vehicle types. This indicates a heightened risk of accidents involving pedestrians in interactions with bicycles and e-bikes. Additionally, an interesting observation arises concerning bicycles, e-bikes, and e-scooters. In these vehicle categories, there is a higher percentage of accidents attributed to driver inattention. Curiously, these do not require a license to drive (except some e-scooters)!\n",
    "\n",
    "Using the right heatmap in the blue-teal pair at the bottom, we can break down the driving infractions that lead to accidents. Here are some notable examples: Firstly, ambulances stand out with a higher percentage of collisions attributed to \"passing too close.\" Similarly, in the case of bicycles, there is a higher percentage of collisions associated with \"Failure to Yield Right of Way\". These are just some highlighted examples, and a more in-depth analysis would reveal additional insights into specific driving infractions contributing to accidents."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
