{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Neteja de Dades<h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>NYC Colissions<h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Vista global de la distribució de les dades i els valors NULL<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = \"./data/original-data.csv\"\n",
    "\n",
    "# Read the data\n",
    "df = pd.read_csv(path)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the CRASH DATE column to datetime format\n",
    "df['CRASH DATE'] = pd.to_datetime(df['CRASH DATE'])\n",
    "\n",
    "# Filter the dataframe to only include rows where the CRASH DATE column is in 2019\n",
    "df_2019 = df[df['CRASH DATE'].dt.year == 2019]\n",
    "\n",
    "# Print the filtered dataframe\n",
    "print(df_2019)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show number of unique values for each column\n",
    "print(df.nunique())\n",
    "\n",
    "# Show value counts for each column\n",
    "for col in df.columns:\n",
    "    print(f\"\\nValue counts for {col}:\")\n",
    "    print(df[col].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show number of missing values for each column\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Borrem Columnes no importants<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns not relevant for our analysis\n",
    "columns_to_drop = ['ZIP CODE', 'LATITUDE', 'LONGITUDE', 'ON STREET NAME', 'CROSS STREET NAME', 'OFF STREET NAME', 'NUMBER OF PEDESTRIANS INJURED', 'NUMBER OF PEDESTRIANS KILLED', 'NUMBER OF CYCLIST INJURED', 'NUMBER OF CYCLIST KILLED', 'NUMBER OF MOTORIST INJURED', 'NUMBER OF MOTORIST KILLED', 'CONTRIBUTING FACTOR VEHICLE 1', 'CONTRIBUTING FACTOR VEHICLE 2', 'CONTRIBUTING FACTOR VEHICLE 3', 'CONTRIBUTING FACTOR VEHICLE 4', 'CONTRIBUTING FACTOR VEHICLE 5', 'COLLISION_ID', 'VEHICLE TYPE CODE 2', 'VEHICLE TYPE CODE 3', 'VEHICLE TYPE CODE 4', 'VEHICLE TYPE CODE 5']\n",
    "df2 = df.drop(columns=columns_to_drop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Solucionem els valors NULL <h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of missing values for each column\n",
    "print(df2.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in missing values with 0 for the following columns:\n",
    "df2['NUMBER OF PERSONS INJURED'].fillna(0, inplace=True)\n",
    "df2['NUMBER OF PERSONS KILLED'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values for the following columns:\n",
    "df2.dropna(subset=['VEHICLE TYPE CODE 1'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of missing values in LOCATION and BOROUGH simultaneously\n",
    "print((df['LOCATION'].isnull() & df['BOROUGH'].isnull()).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values for both LOCATION and BOROUGH\n",
    "df2.dropna(subset=['LOCATION', 'BOROUGH'], how='all', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of missing values for each column\n",
    "print(df2.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values for the following columns:\n",
    "df2.dropna(subset=['LOCATION'], inplace=True)\n",
    "df3 = df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Arrodonir variable CRASH TIME <h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round the values in the CRASH TIME column to the nearest hour\n",
    "df3['CRASH TIME'] = pd.to_datetime(df['CRASH TIME']).dt.round('H').dt.time\n",
    "\n",
    "# Print the updated dataframe\n",
    "print(df3.head())\n",
    "df4 = df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Afegir columnes interessants per a les preguntes a respondre<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column that indicates whether the accident occurred on a weekday or a weekend\n",
    "df4['WEEKDAY'] = pd.to_datetime(df3['CRASH DATE']).dt.dayofweek < 5\n",
    "\n",
    "# Create a new column that indicates whether the accident occurred before or after COVID-19\n",
    "covid_start_date = pd.to_datetime('2020-03-01')\n",
    "df4['BEFORE COVID'] = pd.to_datetime(df3['CRASH DATE']) < covid_start_date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Responent alguna prgunta <h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Are there any areas with a larger number of accidents?<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a bar plot of the number of accidents by borough\n",
    "df4['BOROUGH'].value_counts().plot(kind='bar')\n",
    "plt.title('Number of Accidents by Borough')\n",
    "plt.xlabel('Borough')\n",
    "plt.ylabel('Number of Accidents')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_BOROUGH = {\"Broklin\": 179.7, \"Manhattan\": 58.8, \"Queens\":281.5, \"Bronx\": 109.3, \"Staten Island\": 148.9}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Is there any type of vehicle more prone to participate in accidents?<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "# Create a dataframe with the value counts of the 'VEHICLE TYPE CODE 1' column\n",
    "df_vehicle_counts = df4['VEHICLE TYPE CODE 1'].value_counts().reset_index()\n",
    "df_vehicle_counts.columns = ['Vehicle Type', 'Count']\n",
    "\n",
    "# Create a horizontal bar chart using Altair\n",
    "chart = alt.Chart(df_vehicle_counts[:10]).mark_bar().encode(\n",
    "    y=alt.Y('Vehicle Type:N', sort='-x'),\n",
    "    x=alt.X('Count:Q'),\n",
    "    tooltip=['Vehicle Type', 'Count']\n",
    ").properties(\n",
    "    title='Vehicle Types Involved in Accidents'\n",
    ")\n",
    "\n",
    "chart\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> At what time of the day are accidents more common? <h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the CRASH TIME column to a string\n",
    "df4['CRASH TIME'] = df3['CRASH TIME'].astype(str)\n",
    "\n",
    "# Group the data by hour and count the number of accidents for each hour\n",
    "df_hourly = df4.groupby('CRASH TIME').size().reset_index(name='COUNT')\n",
    "\n",
    "# Create a line chart of the number of accidents by hour using Altair\n",
    "chart = alt.Chart(df_hourly).mark_line().encode(\n",
    "    x='CRASH TIME:O',\n",
    "    y='COUNT:Q'\n",
    ").properties(\n",
    "    title='Number of Accidents by Hour of the Day'\n",
    ")\n",
    "\n",
    "chart\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>¿Cuál es el promedio de personas heridas y personas muertas en los accidentes de vehículos en Nueva York? ¿Ha habido cambios significativos en estos números con el tiempo?<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_injured = df4['NUMBER OF PERSONS INJURED'].mean()\n",
    "print(f\"The mean number of injured people caused by car collisions is {mean_injured:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_killed = df4['NUMBER OF PERSONS KILLED'].mean()\n",
    "print(f\"The mean number of killed people caused by car collisions is {mean_killed:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the CRASH DATE column to a datetime object\n",
    "df4['CRASH DATE'] = pd.to_datetime(df4['CRASH DATE'])\n",
    "\n",
    "# Compute the yearly mean of injured people\n",
    "yearly_mean_injured = df4.groupby(pd.Grouper(key='CRASH DATE', freq='A'))['NUMBER OF PERSONS INJURED'].mean().reset_index()\n",
    "\n",
    "print(yearly_mean_injured)\n",
    "# Plot the yearly mean of injured people using Altair\n",
    "chart = alt.Chart(yearly_mean_injured).mark_line().encode(\n",
    "    x='CRASH DATE:T',\n",
    "    y='NUMBER OF PERSONS INJURED:Q'\n",
    ").properties(\n",
    "    title='Yearly Mean of Injured People in Car Collisions'\n",
    ")\n",
    "\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe to only include rows where the CRASH DATE column is in 2019\n",
    "df_2019 = df4[df4['CRASH DATE'].dt.year == 2019]\n",
    "\n",
    "# Sum the values in the NUMBER OF PERSONS INJURED column\n",
    "num_injured_2019 = df_2019['NUMBER OF PERSONS INJURED'].sum()\n",
    "\n",
    "print(f\"{num_injured_2019} people got injured in 2019\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe to only include rows where the CRASH DATE column is in 2019\n",
    "df_2019 = df4[df4['CRASH DATE'].dt.year == 2019]\n",
    "\n",
    "# Show all the rows from 2019\n",
    "print(df_2019)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
