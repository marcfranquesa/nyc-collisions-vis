{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f06624c8",
   "metadata": {},
   "source": [
    "# VI: First Practical Work\n",
    "\n",
    "**Authors:** Gerard Comas & Marc Franquesa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "import geopandas as gpd\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "collisions = pd.read_csv(\"./processed-data/collisions.csv\")\n",
    "map_data = gpd.read_file(\"./processed-data/map.geojson\")\n",
    "weather = pd.read_csv(\"./processed-data/weather.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03d6d20",
   "metadata": {},
   "source": [
    "## Design and implementation\n",
    "\n",
    "**Q IDEAS:**\n",
    "\n",
    "* Q1: basic barplot?\n",
    "* Q2: slope chart\n",
    "* Q3: histogram?\n",
    "* Q4: basic map plot\n",
    "* Q5:\n",
    "\n",
    "---\n",
    "**O IDEAS:**\n",
    "* Color for vehicle type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658aa12f-7ed0-4877-b5c6-db6a8ca28bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpful functions\n",
    "\n",
    "def before_covid(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df[df[\"AFTER COVID\"] == False]\n",
    "\n",
    "def after_covid(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df[df[\"AFTER COVID\"] == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c81d57-200f-44a8-ab17-dfbf7dc8c6d9",
   "metadata": {},
   "source": [
    "### 1. Are accidents more frequent during weekdays or weekends? Is there any difference between before COVID-19 and after?\n",
    "\n",
    "With an ambitious goal in mind, lets first plot the total collisions of each day of the week before COVID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f09065-124f-4ddb-8c96-91bd9b6aa0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_covid_day_count = before_covid(collisions).groupby([\"CRASH WEEKDAY\"]).size().reset_index(name=\"counts\")\n",
    "\n",
    "weekdayorder = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "\n",
    "alt.Chart(before_covid_day_count).mark_bar().encode(\n",
    "    x = alt.X(\"CRASH WEEKDAY:O\", sort=weekdayorder, axis=alt.Axis(title=\"Week Day\")),\n",
    "    y = alt.Y(\"counts:Q\", axis=alt.Axis(title=\"Collisions\"))\n",
    ").properties(\n",
    "    width=400\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf36cb6-f747-4b61-84dc-aa1b9e7094c2",
   "metadata": {},
   "source": [
    "Lets now make a grouped bar chart, separating before and after covid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803a7124-638c-4b81-8b44-e3811ff52f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "days_df = collisions.groupby([\"CRASH WEEKDAY\", \"AFTER COVID\"]).size().reset_index(name=\"counts\")\n",
    "\n",
    "before, after, all_time = \"Summer 2018 (Before Covid)\", \"Summer 2020 (After Covid)\", \"All\"\n",
    "\n",
    "days_df[\"MOMENT\"] = np.where(days_df[\"AFTER COVID\"], after, before)\n",
    "\n",
    "weekdayorder = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "\n",
    "opacity = 0.5\n",
    "\n",
    "colors = {\n",
    "    before: \"#fdc086\", # Before COVID\n",
    "    after: \"#7fc97f\", # After COVID\n",
    "    all_time: \"#beaed4\"\n",
    "}\n",
    "\n",
    "days_ch = alt.Chart(days_df).mark_bar(\n",
    "    opacity=opacity\n",
    ").encode(\n",
    "   x=alt.X(\"CRASH WEEKDAY:O\", axis=alt.Axis(labelAngle=-30, title=None), sort=weekdayorder),\n",
    "   xOffset=\"MOMENT:O\",\n",
    "   y=alt.Y(\"counts:Q\", axis=alt.Axis(title=\"Collisions\", grid=True)),\n",
    "   color=alt.Color(\"MOMENT:O\", scale=alt.Scale(domain=list(colors.keys()), range=list(colors.values())), legend=alt.Legend(title=None))\n",
    ")\n",
    "\n",
    "days_ch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49eec20a-7fe6-4f04-9198-428e6e6dee7d",
   "metadata": {},
   "source": [
    "Lets now add the average of before and after covid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6ef52c-bdc2-4bba-b10f-e4b6ed372b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "averages = alt.Chart(days_df).mark_rule(opacity=1).encode(\n",
    "    y=\"mean(counts):Q\",\n",
    "    size=alt.value(2),\n",
    "    color=\"MOMENT:O\"\n",
    ")\n",
    "\n",
    "averages + days_ch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544f66b6-a4e5-4538-8aac-96c391db20bd",
   "metadata": {},
   "source": [
    "Lets now separate the days of the week in two categories, weekdays and weekends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c80974a-6de2-4f37-996f-abe6e8b4a57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekdays = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\"]\n",
    "weekends = [\"Saturday\", \"Sunday\"]\n",
    "\n",
    "weekdays_df = days_df[days_df[\"CRASH WEEKDAY\"].isin(weekdays)]\n",
    "weekends_df = days_df[days_df[\"CRASH WEEKDAY\"].isin(weekends)]\n",
    "\n",
    "weekdays_ch = alt.Chart(weekdays_df).mark_bar(opacity=opacity).encode(\n",
    "   x=alt.X(\"CRASH WEEKDAY:O\", axis=alt.Axis(labelAngle=-30, title=None), sort=weekdayorder),\n",
    "   xOffset=\"MOMENT:O\",\n",
    "   y=alt.Y(\"counts:Q\", axis=alt.Axis(title=\"Collisions / Means\", grid=True), scale=alt.Scale(domain=[0, 13000])),\n",
    "   color=alt.Color(\"MOMENT:O\", scale=alt.Scale(domain=list(colors.keys()), range=list(colors.values())))\n",
    ").properties(title=alt.Title(\"Weekdays\", fontSize=10, fontWeight=600))\n",
    "\n",
    "averages_weekday = alt.Chart(weekdays_df).mark_rule(opacity=1).encode(\n",
    "    y=\"mean(counts):Q\",\n",
    "    size=alt.value(2),\n",
    "    color=alt.Color(\"MOMENT:O\")\n",
    ")\n",
    "\n",
    "\n",
    "weekends_ch = alt.Chart(weekends_df).mark_bar(opacity=opacity).encode(\n",
    "   x=alt.X(\"CRASH WEEKDAY:O\", axis=alt.Axis(labelAngle=-30, title=None), sort=weekdayorder),\n",
    "   xOffset=\"MOMENT:O\",\n",
    "   y=alt.Y(\n",
    "       \"counts:Q\",\n",
    "       axis=alt.Axis(title=None, labels=False, domain=False, ticks=False, grid=True),\n",
    "       scale=alt.Scale(domain=[0, 13000])\n",
    "   ),\n",
    "   color=alt.Color(\n",
    "       \"MOMENT:O\",\n",
    "       scale=alt.Scale(domain=list(colors.keys()), range=list(colors.values())),\n",
    "       legend=alt.Legend(title=None)\n",
    "   )\n",
    ").properties(title=alt.Title(\"Weekends\", fontSize=10, fontWeight=600))\n",
    "\n",
    "averages_weekend = alt.Chart(weekends_df).mark_rule(opacity=1).encode(\n",
    "    y=\"mean(counts):Q\",\n",
    "    size=alt.value(2),\n",
    "    color=\"MOMENT:O\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "q1 = ((weekdays_ch + averages_weekday) | (weekends_ch + averages_weekend))\n",
    "\n",
    "q1.configure_legend(symbolOpacity=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac0cf70-159a-4d17-b902-7fef0d9db59a",
   "metadata": {},
   "source": [
    "### 2. Is there any type of vehicle more prone to participate in accidents?\n",
    "Obviously, with the current data we have this is impossible, as cars are the most predominant vehicle by a large margin, meaning they will have the most collisions. Lets start off viewing this data with a simle bar plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886101f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles = collisions.groupby([\"VEHICLE\"]).size().reset_index(name=\"counts\")\n",
    "\n",
    "alt.Chart(vehicles).mark_bar().encode(\n",
    "    y=alt.Y(\"counts:Q\", axis=alt.Axis(title=\"Collisions\")),\n",
    "    x=alt.X(\"VEHICLE:O\", axis=alt.Axis(title=None, labelAngle=-30))\n",
    ").properties(\n",
    "    width=400\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0df887c",
   "metadata": {},
   "source": [
    "This confirms what we hypothesized earlier.\n",
    "\n",
    "La primera idea que vam tenir va ser la de fer un paralel coordinate plane, on tinguessim els seguents plans:\n",
    "- Percentatge d'accidents\n",
    "- Percentatge de circulació\n",
    "- Percentatge de ferits\n",
    "- Percentatge de morts\n",
    "- Ratio de ferits/accident\n",
    "- Ratio de ferits/mort\n",
    "\n",
    "Però a les dades proporcioandes no disposem del percentatge de circulació de cada vehicle i buscant per internet no hem trobat cap dataset que ens pugui proporcionar aquesta informació. Ara mirarem com es distribueixen els seguents plans:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles = collisions[[\"VEHICLE\",\"NUMBER OF PERSONS INJURED\", \"NUMBER OF PERSONS KILLED\"]]\n",
    "vehicles = vehicles[vehicles[\"VEHICLE\"] != \"Unknown\"]\n",
    "\n",
    "vehicles = vehicles.groupby(\"VEHICLE\").agg({\n",
    "    \"VEHICLE\": \"count\",\n",
    "    \"NUMBER OF PERSONS INJURED\": \"sum\",\n",
    "    \"NUMBER OF PERSONS KILLED\": \"sum\"\n",
    "}).rename(columns={\"VEHICLE\": \"COLLISIONS\"}).reset_index()\n",
    "\n",
    "total_collisions = vehicles[\"COLLISIONS\"].sum()\n",
    "\n",
    "# Calcular el número de accidentes por tipo de vehículo\n",
    "vehicles[\"% COLLISIONS\"] = vehicles[\"COLLISIONS\"] / total_collisions * 100\n",
    "\n",
    "# Calcular el número total de personas heridas y muertas en todos los accidentes\n",
    "total_injured = vehicles[\"NUMBER OF PERSONS INJURED\"].sum()\n",
    "total_killed = vehicles[\"NUMBER OF PERSONS KILLED\"].sum()\n",
    "\n",
    "# Calcular los porcentajes de personas heridas y muertas para cada tipo de vehículo\n",
    "vehicles[\"% INJURED\"] = vehicles[\"NUMBER OF PERSONS INJURED\"] / total_injured * 100\n",
    "vehicles[\"% KILLED\"] = vehicles[\"NUMBER OF PERSONS KILLED\"] / total_killed * 100\n",
    "\n",
    "# Calcular los ratios de personas heridas y muertas por accidente para cada tipo de vehículo\n",
    "vehicles[\"INJURED PER COLLISION\"] = vehicles[\"NUMBER OF PERSONS INJURED\"] / vehicles[\"COLLISIONS\"]\n",
    "vehicles[\"KILLED PER COLLISION\"] = vehicles[\"NUMBER OF PERSONS KILLED\"] / vehicles[\"COLLISIONS\"]\n",
    "\n",
    "vehicles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = alt.Chart(vehicles, width=800).transform_window(\n",
    "    index=\"count()\"\n",
    ").transform_fold(\n",
    "    [\"% COLLISIONS\", \"INJURED PER COLLISION\", \"KILLED PER COLLISION\"]\n",
    ").transform_joinaggregate(\n",
    "    min=\"min(value)\",\n",
    "    max=\"max(value)\",\n",
    "    groupby=[\"key\"]\n",
    ").transform_calculate(\n",
    "    norm_val=\"(datum.value - datum.min) / (datum.max - datum.min)\",\n",
    "    mid=\"(datum.min + datum.max) / 2\"\n",
    ")\n",
    "\n",
    "lines = base.mark_line(opacity=0.3).encode(\n",
    "    x=\"key:N\",\n",
    "    y= alt.Y(\"norm_val:Q\", axis=None),\n",
    "    color=\"VEHICLE:N\",\n",
    "    detail=\"index:N\",\n",
    "    opacity=alt.value(0.5)\n",
    ")\n",
    "\n",
    "rules = base.mark_rule(\n",
    "    color=\"#ccc\", tooltip=None\n",
    ").encode(\n",
    "    x=\"key:N\",\n",
    "    detail=\"count():Q\",\n",
    ") \n",
    "\n",
    "def ytick(yvalue, field):\n",
    "    scale = base.encode(x=\"key:N\", y=alt.value(yvalue), text=f\"min({field}):Q\")\n",
    "    return alt.layer(\n",
    "        scale.mark_text(baseline=\"middle\", align=\"right\", dx=-5, tooltip=None),\n",
    "        scale.mark_tick(size=8, color=\"#ccc\", orient=\"horizontal\", tooltip=None)\n",
    "    )\n",
    "\n",
    "alt.layer(\n",
    "    lines, rules ,ytick(0, \"max\"), ytick(150, \"mid\"), ytick(300, \"min\")\n",
    ").configure_axisX(\n",
    "    domain=False, labelAngle=0, tickColor=\"#ccc\", title=None\n",
    ").configure_view(\n",
    "    stroke=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now try a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum = max(vehicles[\"COLLISIONS\"])\n",
    "minimum = min(vehicles[\"COLLISIONS\"])\n",
    "mean = vehicles[\"COLLISIONS\"].mean()\n",
    "\n",
    "# Using purple color as it represents the entire collision count\n",
    "scatter = alt.Chart(vehicles).mark_circle(color=colors[all_time]).encode(\n",
    "    x=alt.X(\"INJURED PER COLLISION:Q\", axis=alt.Axis(title=\"Injured per collision\")),\n",
    "    y=alt.Y(\"KILLED PER COLLISION:Q\", axis=alt.Axis(title=\"Deaths per collision\")),\n",
    "    size=alt.Size(\"COLLISIONS:Q\", scale=alt.Scale(range=[10, 700]), legend=alt.Legend(title=\"Total collisions (min-mean-max)\", values=[minimum, mean, maximum])),\n",
    ").properties(\n",
    "    width=500,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "# Lets add labels for each vehicle\n",
    "labels = scatter.mark_text(\n",
    "    align=\"right\",\n",
    "    dx=-15,\n",
    "    dy=0\n",
    ").encode(\n",
    "    text=\"VEHICLE:N\",\n",
    "    size=alt.value(10)\n",
    ")\n",
    "\n",
    "q2 = scatter + labels\n",
    "\n",
    "q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one seems to be easier to understand and also looks nicer, we have decided to keep this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(q1 & q2).configure_legend(symbolOpacity=1).resolve_scale(size=\"independent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccceb09a",
   "metadata": {},
   "source": [
    "### 3. At what time of the day are accidents more common?\n",
    "Lets make a simpler historgram with the overall average as well as a little mark indicating the max hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7931b9-ec27-4e67-aabd-73760d727cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df = collisions\n",
    "time_df[\"HOUR\"] = pd.to_datetime(time_df[\"CRASH DATETIME\"]).dt.hour\n",
    "time_df = time_df.groupby([\"HOUR\", \"AFTER COVID\"]).size().reset_index(name=\"counts\")\n",
    "\n",
    "time_df[\"MOMENT\"] = np.where(time_df[\"AFTER COVID\"], after, before)\n",
    "\n",
    "time_ch = alt.Chart(time_df).mark_bar(opacity=opacity).encode(\n",
    "    x=alt.X(\"HOUR:O\", axis=alt.Axis(labelAngle=0), title=\"Hour\"),\n",
    "    y=alt.Y(\"counts:Q\", title=\"Collisions / Mean\"),\n",
    "    color=alt.Color(\n",
    "        \"MOMENT:O\",\n",
    "        scale=alt.Scale(domain=list(colors.keys()), range=list(colors.values())),\n",
    "        legend=alt.Legend(title=None)\n",
    "    ),\n",
    "    order=alt.Order(\"MOMENT:O\", sort=\"ascending\")\n",
    ")\n",
    "\n",
    "time_all_df = time_df.groupby([\"HOUR\"]).sum().reset_index()\n",
    "\n",
    "averages_weekend = alt.Chart(time_all_df).mark_rule(opacity=1, color=colors[all_time]).encode(\n",
    "    y=\"mean(counts):Q\",\n",
    "    size=alt.value(2),\n",
    ")\n",
    "\n",
    "max_hour = alt.Chart().mark_text(text=str(sum(time_df.loc[time_df[\"HOUR\"] == 16, \"counts\"])), angle=0).encode(\n",
    "    x=alt.value(330),\n",
    "    y=alt.value(20),\n",
    ")\n",
    "\n",
    "q3 = (time_ch + averages_weekend + max_hour)\n",
    "q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d586f5-be41-4b64-8e25-f797640275c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "((q1 | q3) & q2).configure_legend(symbolOpacity=1).resolve_scale(size=\"independent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e09726",
   "metadata": {},
   "source": [
    "### 4. Are there any areas with a larger number of accidents?\n",
    "Lets make a choropleth map. First, lets just a couple collisions in NYC. We are using a district map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c033f70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = alt.Chart(map_data).mark_geoshape(fill=\"lightgray\", stroke=\"black\").project(type=\"albersUsa\").properties(\n",
    "    width=700,\n",
    "    height=700\n",
    ")\n",
    "\n",
    "pts = alt.Chart(collisions[collisions[\"LOCATION\"].notna()].head(5000)).mark_circle().encode(\n",
    "    latitude=\"LATITUDE\",\n",
    "    longitude=\"LONGITUDE\",\n",
    "    color='BOROUGH',\n",
    "    tooltip=['LATITUDE', \"LONGITUDE\"]\n",
    ")\n",
    "\n",
    "(base + pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d44e4fe",
   "metadata": {},
   "source": [
    "Now making the Choropleth Map! We will be using the purple scale as we will be using the entire dataset, not just before/after covid. Keep in mind that we will only be looking at area, there are other factors too, like total km of streets. However, we have decided to go with this path as any other variable would be tricky to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23899598",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = alt.Chart(map_data).mark_geoshape().project(type=\"albersUsa\").encode(\n",
    "    color=alt.Color(\"collision_count:Q\", scale=alt.Scale(scheme='purples'), legend=alt.Legend(title=\"Collisions\")),\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=600,\n",
    "    title=\"NYC Community Districts\"\n",
    ")\n",
    "\n",
    "base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6681777",
   "metadata": {},
   "source": [
    "Lets add labels to the top 3 areas with most collisions. Only 3 as getting too many more would overcrowd the map. Getting the labels from [here](https://furmancenter.org/files/sotc/SOC2007_IndexofCommunityDistricts_000.pdf). Using the centroids of the areas to get where to place the labels. Lets see how that looks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cd76ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "top = map_data.sort_values(by=\"collision_count\", ascending=False).head(3)\n",
    "top[[\"LATITUDE\", \"LONGITUDE\"]] = top[\"geometry\"].centroid.apply(lambda x: pd.Series([x.y, x.x]))\n",
    "\n",
    "# \n",
    "labels = {\n",
    "    \"boro_cd\": [\"412\", \"413\", \"305\"],\n",
    "    \"LABELS\": [\"Jamaica / Hollis\", \"Queens Village\", \"East New York\"]\n",
    "}\n",
    "\n",
    "top = top.merge(pd.DataFrame(labels), left_on=\"boro_cd\", right_on=\"boro_cd\")\n",
    "\n",
    "text_labels = alt.Chart(top).mark_text(angle=0, dx=0, dy=0, fill=\"white\", size=8).encode(\n",
    "    longitude='LONGITUDE:Q',\n",
    "    latitude='LATITUDE:Q',\n",
    "    text='LABELS:N',\n",
    ")\n",
    "\n",
    "base + text_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0162fc",
   "metadata": {},
   "source": [
    "Labels are good except the Queens Village, which is barely visible. Lets place it where it can be read correctly. And lets add a couple icons for \"interesting vehicles\"!. These icons will be wherever they collided!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3ac60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top.loc[top[\"LABELS\"] == \"Queens Village\", [\"LATITUDE\", \"LONGITUDE\"]] = [40.66605, -73.75998]\n",
    "\n",
    "\n",
    "text_labels = alt.Chart(top).mark_text(angle=0, dx=0, dy=0, fill=\"white\", size=9).encode(\n",
    "    longitude=\"LONGITUDE:Q\",\n",
    "    latitude=\"LATITUDE:Q\",\n",
    "    text=\"LABELS:N\",\n",
    ")\n",
    "\n",
    "\n",
    "horse = alt.Chart(collisions[collisions[\"ORIGINAL VEHICLE\"] == \"Horse\"]).mark_text(text=\"🐎\", size=18).encode(\n",
    "    longitude=\"LONGITUDE:Q\",\n",
    "    latitude=\"LATITUDE:Q\",\n",
    ")\n",
    "\n",
    "gokart = alt.Chart(collisions[collisions[\"ORIGINAL VEHICLE\"] == \"Go kart\"]).mark_text(text=\"🏎️\", size=18).encode(\n",
    "    longitude=\"LONGITUDE:Q\",\n",
    "    latitude=\"LATITUDE:Q\",\n",
    ")\n",
    "\n",
    "\n",
    "q4 = (base + text_labels + horse + gokart).properties(width=600, height=600)\n",
    "\n",
    "q4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020303f6",
   "metadata": {},
   "source": [
    "Great! Lets now put it all together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aff4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "((q4 | (q1 & q3)) & q2).configure_legend(symbolOpacity=1).resolve_scale(size=\"independent\", color=\"shared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.  Is there a correlation between weather conditions and accidents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read weather data\n",
    "weather = pd.read_csv(\"./processed-data/weather.csv\")\n",
    "\n",
    "weather_corr = weather.drop(columns=[\"valid\"]).corr()\n",
    "weather_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the data into a long format\n",
    "corr_long = weather_corr.stack().reset_index()\n",
    "corr_long.columns = ['x', 'y', 'value']\n",
    "\n",
    "# create the heatmap\n",
    "heatmap = alt.Chart(corr_long).mark_rect().encode(\n",
    "    x='x:O',\n",
    "    y='y:O',\n",
    "    color='value:Q'\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "# add text to the heatmap\n",
    "text = heatmap.mark_text(baseline='middle').encode(\n",
    "    text=alt.Text('value:Q', format='.2f'),\n",
    "    color=alt.condition(\n",
    "        alt.datum.value > 0.5,\n",
    "        alt.value('white'),\n",
    "        alt.value('black')\n",
    "    )\n",
    ")\n",
    "\n",
    "heatmap + text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this heatmap, we can see that there is a significant relationship between the columns `vsby` and `relh`; low visibility values are associated with high relative humidity values. There is also a strong correlation between the columns `relh` and `tmpf`. All of this makes a lot of sense when we consider the thermodynamics relation between climatic variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the collision dataset\n",
    "collisions['DATE'] = pd.to_datetime(collisions['CRASH DATETIME'])\n",
    "weather['DATE'] = pd.to_datetime(weather['valid'])\n",
    "\n",
    "\n",
    "# merge the two datasets on the common column \"DATE\"\n",
    "collisions_weather = pd.merge(collisions, weather, on=\"DATE\")\n",
    "\n",
    "# print the merged dataset\n",
    "print(collisions_weather.columns)\n",
    "\n",
    "# select the columns we want to keep\n",
    "collisions_weather_selected  = collisions_weather[['DATE', 'NUMBER OF PERSONS INJURED', 'NUMBER OF PERSONS KILLED', 'VEHICLE',  'tmpf', 'relh', 'sknt', 'p01i', 'vsby']]\n",
    "\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def violinPlot(dataset, column, rang):\n",
    "    color = '#7fc97fbb' if dataset.equals(weather) else '#beaed4'\n",
    "    title = 'Normal' if dataset.equals(weather) else 'Collisions'\n",
    "    orient = 'right' if dataset.equals(weather) else 'left'\n",
    "    chart = alt.Chart(dataset , width=100).transform_density(\n",
    "        column,\n",
    "        as_=[column, 'density'],\n",
    "        extent= rang\n",
    "    ).mark_area(orient='horizontal', color = color).encode(\n",
    "        alt.X('density:Q')\n",
    "            .stack('center')\n",
    "            .impute(None)\n",
    "            .title(None)\n",
    "            .axis(labels=False, values=[0], grid=False, ticks=True),\n",
    "        alt.Y(column + ':Q').title(title).axis(titleColor=color, orient=orient)\n",
    "    )\n",
    "\n",
    "    # Calculate quartiles\n",
    "    q1 = dataset[column].quantile(0.25)\n",
    "    q2 = dataset[column].quantile(0.5)\n",
    "    q3 = dataset[column].quantile(0.75)\n",
    "\n",
    "    # Add quartiles as horizontal lines\n",
    "    q1_r = alt.Chart(pd.DataFrame({'y': [q1]})).mark_rule(color='#fee0d2', strokeWidth=2).encode(y='y')\n",
    "    q2_r = alt.Chart(pd.DataFrame({'y': [q2]})).mark_rule(color='#fc9272', strokeWidth=2).encode(y='y')\n",
    "    q3_r = alt.Chart(pd.DataFrame({'y': [q3]})).mark_rule(color='#de2d26', strokeWidth=2).encode(y='y')\n",
    "\n",
    "    return chart + q1_r + q2_r + q3_r\n",
    "\n",
    "(violinPlot(collisions_weather_selected, 'tmpf', [5, 45]) | \n",
    " violinPlot(weather, 'tmpf', [5, 45])\n",
    ").properties(\n",
    "    title = \"Temperature\"\n",
    ") | (violinPlot(collisions_weather_selected, 'relh', [0, 100]) | \n",
    " violinPlot(weather, 'relh', [0, 100])\n",
    ").properties(\n",
    "    title = \"Humidity\"\n",
    ") | (violinPlot(collisions_weather_selected, 'sknt', [0, 25]) | \n",
    " violinPlot(weather, 'sknt', [0, 25])\n",
    ").properties(\n",
    "    title = \"Speed of wind\"\n",
    ") | (violinPlot(collisions_weather_selected, 'p01i', [0, 0.5]) | \n",
    " violinPlot(weather, 'p01i', [0, 0.5])\n",
    ").properties(\n",
    "    title = \"Rainfall level\"\n",
    ") | (violinPlot(collisions_weather_selected, 'vsby', [0, 20]) | \n",
    " violinPlot(weather, 'vsby', [0, 20])\n",
    ").properties(\n",
    "    title = \"Visibility\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this plot, we can compare the distribution of climatic variables when accidents occur versus their distribution at all times. The intention behind creating this graph was to help us understand if these distributions vary when accidents happen, that is, whether certain meteorological variables affect the number of accidents.\n",
    "\n",
    "In some cases, we observe slightly different distributions, but it's not easy to compare them directly in this form. We need to find another way to address the question. The idea will be to look for the most extreme cases. We'll start with visibility, where we clearly see that the first quartile is at a lower level when accidents occur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Visibility in accidents: {collisions_weather_selected['vsby'].describe()}\")\n",
    "print(f\"Visibility  in general: {weather['vsby'].describe()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this data, it can be concluded that when visibility is lower, there are more accidents, as indicated by the lower mean and the lower first quartile. The other quartiles are at a value of 16.093440 kilometers, equivalent to 10 miles, which is considered complete visibility according to the data source.\n",
    "\n",
    "However, it would be essential to study the probability of an accident with low visibility compared to the probability of an accident with high visibility.\n",
    "\n",
    "A clearer way to represent this would be the following:\n",
    "\n",
    "Histogram where the X-axis represents visibility, and the Y-axis represents the number of accidents/occurrences in weather conditions.\n",
    "This way, we can determine the collision ratio, providing more valuable information about the likelihood of accidents concerning different visibility conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 17 bins for the vsby column\n",
    "bins = pd.cut(collisions_weather_selected.dropna(subset=[\"vsby\"])[\"vsby\"], bins=17, labels=list(range(17)))\n",
    "\n",
    "# group by the bins\n",
    "grouped = collisions_weather_selected.groupby(bins)\n",
    "\n",
    "# get the count of collisions in each bin\n",
    "counts = grouped.size()\n",
    "\n",
    "\n",
    "# create 17 bins for the vsby column\n",
    "bins_weather = pd.cut(weather.dropna(subset=[\"vsby\"])['vsby'], bins=17, labels=range(17))\n",
    "\n",
    "# group by the bins\n",
    "grouped_weather = weather.groupby(bins_weather)\n",
    "\n",
    "# get the count of collisions in each bin\n",
    "counts_weather = grouped_weather.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe with counts and counts_weather\n",
    "df = pd.DataFrame({'counts': counts, 'counts_weather': counts_weather})\n",
    "\n",
    "# create a new column with the ratio of counts to counts_weather\n",
    "df['ratio'] = df['counts'] / df['counts_weather']\n",
    "\n",
    "df['visibility'] = df.index \n",
    "\n",
    "# create the bar chart\n",
    "chart = alt.Chart(df).mark_bar().encode(\n",
    "    x=alt.X('visibility:O', axis=alt.Axis(title='Visibility')),\n",
    "    y=alt.Y('ratio:Q', axis=alt.Axis(title='Ratio of Collisions')),\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# add the mean to the plot\n",
    "mean_line = alt.Chart(df).mark_rule(color='red', strokeDash=[5,5]).encode(\n",
    "    y='mean(ratio):Q'\n",
    ")\n",
    "\n",
    "chart + mean_line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It could be beneficial for the user to understand how far each data point is from the average value. To achieve this, we will calculate the z-score for each data point, which measures the number of standard deviations a particular data point is from the mean. By plotting the data using a divergent color scheme based on the z-scores, we can emphasize the more extreme values in the dataset. This visual representation will highlight instances where the data significantly deviates from the mean, providing a clearer insight into the distribution and identifying any outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean and standard deviation of the ratio\n",
    "mean_ratio = df['ratio'].mean()\n",
    "std_ratio = df['ratio'].std()\n",
    "\n",
    "# calculate the Z-Score for each data point\n",
    "df['z_score'] = (df['ratio'] - mean_ratio) / std_ratio\n",
    "\n",
    "# create the scatter plot\n",
    "scatter = alt.Chart(df).mark_circle().encode(\n",
    "    x=alt.X('visibility:O', axis=alt.Axis(title='Visibility')),\n",
    "    y=alt.Y('z_score:Q', axis=alt.Axis(title='Z-Score of Ratio')),\n",
    "    color=alt.Color('z_score:Q', scale=alt.Scale(scheme='purplegreen')),\n",
    "    tooltip=['visibility', 'z_score']\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "# add the mean line to the plot\n",
    "mean_line = alt.Chart(df).mark_rule(color='red', strokeDash=[5,5]).encode(\n",
    "    y='mean(z_score):Q'\n",
    ")\n",
    "\n",
    "scatter + mean_line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we can do is combine the two graphs, and we have the following solutions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe with counts and counts_weather\n",
    "df = pd.DataFrame({'counts': counts, 'counts_weather': counts_weather})\n",
    "\n",
    "# create a new column with the ratio of counts to counts_weather\n",
    "df['ratio'] = df['counts'] / df['counts_weather']\n",
    "\n",
    "df['visibility'] = df.index \n",
    "\n",
    "mean_ratio = df['ratio'].mean()\n",
    "std_ratio = df['ratio'].std()\n",
    "\n",
    "df['pstd'] = mean_ratio + 2*std_ratio\n",
    "df['nstd'] = mean_ratio - 2*std_ratio\n",
    "\n",
    "# calculate the Z-Score for each data point\n",
    "df['z_score'] = (df['ratio'] - mean_ratio) / std_ratio\n",
    "\n",
    "# create the bar chart\n",
    "bar = alt.Chart(df).mark_bar().encode(\n",
    "    x=alt.X('visibility:O', axis=alt.Axis(title='Visibility')),\n",
    "    y=alt.Y('ratio:Q', axis=alt.Axis(title='Ratio of Collisions')),\n",
    "    color=alt.Color('z_score:Q', scale=alt.Scale(scheme='purplegreen'), legend = alt.Legend(title='Z-Score of Ratio'))\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "# create the bar chart\n",
    "rule = alt.Chart(df).mark_rule().encode(\n",
    "    x=alt.X('visibility:O', axis=alt.Axis(title='Visibility')),\n",
    "    y=alt.Y('ratio:Q', axis=alt.Axis(title='Ratio of Collisions')),\n",
    "    color=alt.Color('z_score:Q', scale=alt.Scale(scheme='purplegreen'), legend = None)\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "# create the bar chart\n",
    "point = alt.Chart(df).mark_circle().encode(\n",
    "    x=alt.X('visibility:O', axis=alt.Axis(title='Visibility')),\n",
    "    y=alt.Y('ratio:Q', axis=alt.Axis(title='Ratio of Collisions')),\n",
    "    color=alt.Color('z_score:O', scale=alt.Scale(scheme='purplegreen'), legend= None)\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "# add the mean to the plot\n",
    "mean_line = alt.Chart(df).mark_rule(color='gray', strokeDash=[5,5]).encode(\n",
    "    y='mean(ratio):Q'\n",
    ")\n",
    "\n",
    "pstd_line = alt.Chart(df).mark_rule(color='black', strokeDash=[5,5]).encode(\n",
    "    y='pstd:Q'\n",
    ")\n",
    "\n",
    "nstd_line = alt.Chart(df).mark_rule(color='black', strokeDash=[5,5]).encode(\n",
    "    y='nstd:Q'\n",
    ")\n",
    "\n",
    "(bar + mean_line + pstd_line + nstd_line) | (rule + point + mean_line + pstd_line + nstd_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot indicates a noticeable trend: as visibility decreases, the likelihood of an accident appears to increase. This observation is supported by the analysis of Z-Scores, which suggests that instances of extremely low visibility, represented by points around 1.5 standard deviations below the mean, are associated with a higher probability of accidents. In simpler terms, when visibility is severely reduced, the data suggests a greater chance of accidents occurring. This aligns with the common understanding that adverse weather conditions leading to poor visibility can contribute to an elevated risk of accidents.\n",
    "\n",
    "\n",
    "Still, a doubt arises: why are the results less conclusive than expected? This is because visibility is closely related to humidity, and humidity, in turn, is related to temperature, which is highly influenced by the time of day. Therefore, we can imagine that the hours with lower visibility coincide with the hours when there are fewer accidents. This is something we will verify shortly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the hour from the DATE column\n",
    "collisions_weather_selected['HOUR'] = collisions_weather_selected['DATE'].dt.hour\n",
    "\n",
    "# group by hour and calculate the mean of the visibility column\n",
    "mean_visibility = collisions_weather_selected.groupby('HOUR')['vsby'].mean()\n",
    "\n",
    "\n",
    "# create a chart with the mean visibility by hour\n",
    "visby_hour = alt.Chart(mean_visibility.reset_index()).mark_bar().encode(\n",
    "    x=alt.X('HOUR:O', axis=alt.Axis(title='Hour')),\n",
    "    y=alt.Y('vsby:Q', axis=alt.Axis(title='Mean Visibility')),\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "# add the mean line\n",
    "mean_line = alt.Chart(mean_visibility.reset_index()).mark_rule(color='red', strokeDash=[5,5]).encode(\n",
    "    y='mean(vsby):Q'\n",
    ")\n",
    "\n",
    "visby_hour + mean_line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that between 6 and 7 a.m. are the hours with the least visibility, coinciding with hours with fewer collisions. This is not a causal relationship, meaning that lower visibility doesn't directly cause fewer accidents; that wouldn't make sense. Instead, the hours with lower visibility align with times when fewer people are driving, and therefore, there are fewer accidents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column with the visibility category\n",
    "collisions_weather_selected['VISIBILITY CATEGORY'] = np.where(collisions_weather_selected['vsby'] > 16, 'High Visibility', 'Low Visibility')\n",
    "\n",
    "# group by hour and visibility category and calculate the count of collisions\n",
    "hourly_visibility = collisions_weather_selected.groupby(['HOUR', 'VISIBILITY CATEGORY']).size().reset_index(name='counts')\n",
    "\n",
    "\n",
    "# calculate the total number of collisions per hour\n",
    "hourly_total = hourly_visibility.groupby('HOUR')['counts'].sum().reset_index(name='total')\n",
    "\n",
    "# merge the hourly_visibility and hourly_total dataframes\n",
    "hourly_visibility = pd.merge(hourly_visibility, hourly_total, on='HOUR')\n",
    "\n",
    "# calculate the percentage of low and high visibility collisions\n",
    "hourly_visibility['percentage'] = hourly_visibility['counts'] / hourly_visibility['total'] * 100\n",
    "\n",
    "# create the stacked bar chart\n",
    "stacked_bar = alt.Chart(hourly_visibility).mark_bar().encode(\n",
    "    x=alt.X('HOUR:O', axis=alt.Axis(title='Hour')),\n",
    "    y=alt.Y('percentage:Q', axis=alt.Axis(title='Percentage of Collisions')),\n",
    "    color=alt.Color('VISIBILITY CATEGORY:N', scale=alt.Scale(domain=['Low Visibility', 'High Visibility'], range=['#1f77b4', '#ff7f0e']), legend=alt.Legend(title='Visibility Category'))\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "stacked_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rainfall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now do the same with rainfall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# select the rows where p01i is 0\n",
    "zero_p01i = collisions_weather_selected.loc[collisions_weather_selected['p01i'] == 0]\n",
    "\n",
    "# get the number of rows with p01i = 0\n",
    "num_zero_p01i = len(zero_p01i)\n",
    "\n",
    "# select the rows where p01i is not 0\n",
    "nonzero_p01i = collisions_weather_selected.loc[collisions_weather_selected['p01i'] != 0]\n",
    "\n",
    "# create 10 bins for the p01i column\n",
    "bins = pd.cut(nonzero_p01i['p01i'], bins=10)\n",
    "\n",
    "# get the midpoint of each interval\n",
    "midpoints = bins.apply(lambda x: x.mid.round(2))\n",
    "\n",
    "# group by the midpoints\n",
    "grouped = nonzero_p01i.groupby(midpoints)\n",
    "\n",
    "# convert the result of the groupby to a dataframe\n",
    "grouped_df = grouped.size().reset_index(name='counts')\n",
    "\n",
    "# create a new dataframe with the count of rows with p01i = 0\n",
    "zero_row = pd.DataFrame({'p01i': [0], 'counts': [num_zero_p01i]})\n",
    "\n",
    "counts = pd.merge(zero_row , grouped_df, on=['p01i', 'counts'], how=\"outer\", indicator=False)\n",
    "\n",
    "# select the rows where p01i is 0\n",
    "zero_p01i_weather = weather.loc[weather['p01i'] == 0]\n",
    "\n",
    "# get the number of rows with p01i = 0\n",
    "num_zero_p01i_weather = len(zero_p01i_weather)\n",
    "\n",
    "# select the rows where p01i is not 0\n",
    "nonzero_p01i_weather = weather.loc[weather['p01i'] != 0]\n",
    "\n",
    "# create 10 bins for the p01i column\n",
    "bins_weather = pd.cut(nonzero_p01i_weather['p01i'], bins=10)\n",
    "\n",
    "# get the midpoint of each interval\n",
    "midpoints_weather = bins_weather.apply(lambda x: x.mid.round(2))\n",
    "\n",
    "# group by the midpoints\n",
    "grouped_weather = nonzero_p01i_weather.groupby(midpoints_weather)\n",
    "\n",
    "# convert the result of the groupby to a dataframe\n",
    "grouped_df_weather = grouped_weather.size().reset_index(name='counts')\n",
    "\n",
    "# create a new dataframe with the count of rows with p01i = 0\n",
    "zero_row_weather = pd.DataFrame({'p01i': [0], 'counts': [num_zero_p01i_weather]})\n",
    "\n",
    "counts_weather= pd.merge(zero_row_weather, grouped_df_weather, on=['p01i', 'counts'], how=\"outer\", indicator=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe with counts and counts_weather\n",
    "df = pd.DataFrame({'p01i': counts['p01i'] ,'counts': counts['counts'], 'counts_weather': counts_weather['counts']})\n",
    "\n",
    "# create a new column with the ratio of counts to counts_weather\n",
    "df['ratio'] = df['counts'] / df['counts_weather']\n",
    "\n",
    "mean_ratio = df['ratio'].mean()\n",
    "std_ratio = df['ratio'].std()\n",
    "\n",
    "df['mean'] = mean_ratio\n",
    "df['pstd'] = mean_ratio + 2*std_ratio\n",
    "df['nstd'] = mean_ratio - 2*std_ratio\n",
    "\n",
    "# calculate the Z-Score for each data point\n",
    "df['z_score'] = (df['ratio'] - mean_ratio) / std_ratio\n",
    "\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# create the bar chart\n",
    "bar = alt.Chart(df).mark_bar().encode(\n",
    "    x=alt.X('p01i:O', axis=alt.Axis(title='Rain level')),\n",
    "    y=alt.Y('ratio:Q', axis=alt.Axis(title='Ratio of Collisions')),\n",
    "    color=alt.Color('z_score:Q', scale=alt.Scale(scheme='purplegreen'), legend = alt.Legend(title='Z-Score of Ratio'))\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "# create the bar chart\n",
    "rule = alt.Chart(df).mark_rule().encode(\n",
    "    x=alt.X('p01i:O', axis=alt.Axis(title='Rain level')),\n",
    "    y=alt.Y('ratio:Q', axis=alt.Axis(title='Ratio of Collisions')),\n",
    "    color=alt.Color('z_score:Q', scale=alt.Scale(scheme='purplegreen'), legend = None)\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "# create the bar chart\n",
    "point = alt.Chart(df).mark_circle().encode(\n",
    "    x=alt.X('p01i:O', axis=alt.Axis(title='Rain Level')),\n",
    "    y=alt.Y('ratio:Q', axis=alt.Axis(title='Ratio of Collisions')),\n",
    "    color=alt.Color('z_score:O', scale=alt.Scale(scheme='purplegreen'), legend= None)\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "# add the mean to the plot\n",
    "mean_line = alt.Chart(df).mark_rule(color='gray', strokeDash=[5,5]).encode(\n",
    "    y='mean:Q'\n",
    ")\n",
    "\n",
    "pstd_line = alt.Chart(df).mark_rule(color='black', strokeDash=[5,5]).encode(\n",
    "    y='pstd:Q'\n",
    ")\n",
    "\n",
    "nstd_line = alt.Chart(df).mark_rule(color='black', strokeDash=[5,5]).encode(\n",
    "    y='nstd:Q'\n",
    ")\n",
    "\n",
    "(bar + mean_line + pstd_line + nstd_line) | (rule + point + mean_line + pstd_line + nstd_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result we might expect is that the collision ratio increases as the rainfall level rises, and this is true up to values of 2.69 cm of rainfall. Except for the bar at 2.28, as it seems to be an outlier, indicating only one occurrence of rain in that interval. It is also surprising that the ratio decreases for 3.93, but again, this is an outlier that has only occurred once. As a solution, we could consider creating the following plot: raining vs. not raining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the rows where p01i is 0\n",
    "zero_p01i = collisions_weather_selected.loc[collisions_weather_selected['p01i'] == 0]\n",
    "\n",
    "# get the number of rows with p01i = 0\n",
    "num_zero_p01i = len(zero_p01i)\n",
    "\n",
    "# select the rows where p01i is not 0\n",
    "nonzero_p01i = collisions_weather_selected.loc[collisions_weather_selected['p01i'] != 0]\n",
    "\n",
    "# get the number of rows with p01i = 0\n",
    "num_nonzero_p01i = len(nonzero_p01i)\n",
    "\n",
    "# create a new dataframe with the count of rows with p01i = 0\n",
    "zero_row = pd.DataFrame({'p01i': [0], 'counts': [num_zero_p01i]})\n",
    "\n",
    "non_zero_row = pd.DataFrame({'p01i': [1], 'counts': [num_nonzero_p01i]})\n",
    "\n",
    "counts = pd.merge(zero_row , non_zero_row, on=['p01i', 'counts'], how=\"outer\", indicator=False)\n",
    "\n",
    "# select the rows where p01i is 0\n",
    "zero_p01i_weather = weather.loc[weather['p01i'] == 0]\n",
    "\n",
    "# get the number of rows with p01i = 0\n",
    "num_zero_p01i_weather = len(zero_p01i_weather)\n",
    "\n",
    "# select the rows where p01i is not 0\n",
    "nonzero_p01i_weather = weather[weather['p01i'] != 0]\n",
    "\n",
    "# get the number of rows with p01i = 0\n",
    "num_nonzero_p01i_weather = len(nonzero_p01i_weather)\n",
    "\n",
    "# create a new dataframe with the count of rows with p01i = 0\n",
    "zero_row_weather = pd.DataFrame({'p01i': [0], 'counts': [num_zero_p01i_weather]})\n",
    "\n",
    "non_zero_row_weather = pd.DataFrame({'p01i': [1], 'counts': [num_nonzero_p01i_weather]})\n",
    "\n",
    "counts_weather = pd.merge(zero_row_weather , non_zero_row_weather, on=['p01i', 'counts'], how=\"outer\", indicator=False)\n",
    "\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe with counts and counts_weather\n",
    "df = pd.DataFrame({'p01i': counts['p01i'] ,'counts': counts['counts'], 'counts_weather': counts_weather['counts']})\n",
    "\n",
    "# create a new column with the ratio of counts to counts_weather\n",
    "df['ratio'] = df['counts'] / df['counts_weather']\n",
    "\n",
    "# create the bar chart\n",
    "bar = alt.Chart(df).mark_bar().encode(\n",
    "    x=alt.X('p01i:O', axis=alt.Axis(title='Rain level')),\n",
    "    y=alt.Y('ratio:Q', axis=alt.Axis(title='Ratio of Collisions')),\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "bar "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
