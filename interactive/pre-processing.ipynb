{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI: Second Practical Work\n",
    "\n",
    "**Authors:** Gerard Comas & Marc Franquesa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "Processing all datasets in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "import geopandas as gpd\n",
    "import warnings\n",
    "from shapely.geometry import shape, Point\n",
    "import math\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collisions dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the dataset\n",
    "collisions = pd.read_csv(\"./original-data/collisions.csv\")\n",
    "collisions[\"CRASH DATETIME\"] = pd.to_datetime(collisions[\"CRASH DATETIME\"])\n",
    "\n",
    "collisions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only the values from 2018\n",
    "collisions = collisions[collisions[\"CRASH DATETIME\"] < \"2019-01-01\"] \n",
    "\n",
    "# select only the columns we need\n",
    "collisions = collisions[[\"CRASH DATETIME\", \"LATITUDE\", \"LONGITUDE\", \"ORIGINAL VEHICLE\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {\n",
    "    \"Taxi\": [\"Taxi\"],\n",
    "    \"Ambulance\": [\"Ambulance\", \"AMBUL\", \"Ambul\", \"ambul\", \"AMB\", \"AMBU\", \"AMBULANCE\"],\n",
    "    \"Fire truck\": [\"Fire\", \"FIRET\", \"FIRE\", \"FDNY\", \"fdny\", \"FD tr\", \"fd tr\", \"firet\", \"fire\"],\n",
    "}\n",
    "\n",
    "reverse_categories = {val: key for key, values in categories.items() for val in values}\n",
    "\n",
    "# Assume df is your DataFrame and 'column_name' is the column you want to classify\n",
    "collisions[\"VEHICLE\"] = collisions[\"ORIGINAL VEHICLE\"].map(reverse_categories)\n",
    "\n",
    "collisions = collisions.dropna(subset=[\"VEHICLE\"])\n",
    "\n",
    "collisions = collisions[[\"CRASH DATETIME\", \"LATITUDE\", \"LONGITUDE\", \"VEHICLE\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets add emojis\n",
    "vehicle_emojis = {\n",
    "    \"Taxi\": \"🚕\",\n",
    "    \"Ambulance\": \"🚑\",\n",
    "    \"Fire truck\": \"🚒\",\n",
    "}\n",
    "\n",
    "collisions[\"VEHICLE EMOJI\"] = collisions[\"VEHICLE\"].map(vehicle_emojis)\n",
    "\n",
    "collisions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add day information\n",
    "collisions[\"CRASH DAY\"] = collisions[\"CRASH DATETIME\"].dt.strftime(\"%Y-%m-%d\")\n",
    "collisions[\"CRASH WEEKDAY\"] = collisions[\"CRASH DATETIME\"].dt.day_name()\n",
    "collisions[\"CRASH WEEK NUMBER\"] = collisions[\"CRASH DATETIME\"].dt.isocalendar().week\n",
    "collisions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv(\"./original-data/weather2018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = weather[[\"datetime\", \"icon\"]]\n",
    "weather[\"WEATHER\"] = weather[\"icon\"]\n",
    "weather[\"WEATHER\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_emojis = {\n",
    "    \"rain\" : \"🌧\",\n",
    "    \"clear-day\" : \"☀️\",\n",
    "    \"cloudy\" : \"☁️\",\n",
    "    \"partly-cloudy-day\" : \"⛅️\",\n",
    "}\n",
    "\n",
    "weather[\"WEATHER EMOJI\"] = weather[\"WEATHER\"].map(weather_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collisions + Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the collisions and weather dataframes on the \"CRASH DAY\" and \"datetime\" columns\n",
    "collisions_weather = pd.merge(collisions, weather, left_on=\"CRASH DAY\", right_on=\"datetime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NY Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_data = gpd.read_file(f\"./original-data/map.geojson\")\n",
    "\n",
    "collisions_weather[\"BOROUGH\"] = collisions_weather.apply(lambda x: [-1] if pd.isnull(x[\"LATITUDE\"]) or pd.isnull(x[\"LONGITUDE\"]) else np.where(map_data.contains(Point(x[\"LONGITUDE\"], x[\"LATITUDE\"])))[0], axis=1)\n",
    "\n",
    "collisions_weather[\"BOROUGH\"] = collisions_weather[\"BOROUGH\"].apply(lambda x: -1 if len(x) == 0 else x[0]).replace(-1, np.nan)\n",
    "\n",
    "collisions_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_data[\"COLLISIONS\"] = collisions_weather.groupby([\"BOROUGH\"]).size()\n",
    "\n",
    "map_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boroughs = {\n",
    "    0.0: \"Staten Island\",\n",
    "    1.0: \"Bronx\",\n",
    "    2.0: \"Queens\",\n",
    "    3.0: \"Manhattan\",\n",
    "    4.0: \"Brooklyn\"\n",
    "}\n",
    "\n",
    "collisions_weather[\"BOROUGH\"] = collisions_weather[\"BOROUGH\"].map(boroughs)\n",
    "\n",
    "collisions_weather = collisions_weather[[\"CRASH DATETIME\", \"CRASH DAY\", \"CRASH WEEK NUMBER\", \"CRASH WEEKDAY\", \"BOROUGH\", \"VEHICLE\", \"VEHICLE EMOJI\", \"WEATHER\", \"WEATHER EMOJI\"]]\n",
    "\n",
    "collisions_weather.to_csv(\"./processed-data/collisions_weather.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to epsh = 4326\n",
    "# map_data[\"geometry\"] = map_data[\"geometry\"].to_crs(epsg=4326)\n",
    "\n",
    "map_data[\"AREA\"] = map_data[\"geometry\"].area\n",
    "\n",
    "map_data[\"AREA PROPORTION\"] = map_data[\"AREA\"] / map_data[\"AREA\"].sum()\n",
    "\n",
    "# Value found online (wikipedia)\n",
    "map_data[\"AREA KM2\"] = 783.84 * map_data[\"AREA PROPORTION\"]\n",
    "\n",
    "map_data[\"COLLISIONS / KM2\"] = map_data[\"COLLISIONS\"] / map_data[\"AREA KM2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_data.to_file(\"processed-data/map.geojson\", driver=\"GeoJSON\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
