{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f06624c8",
   "metadata": {},
   "source": [
    "# VI: First Practical Work\n",
    "\n",
    "**Authors:** Gerard Comas & Marc Franquesa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a211cc-a9d5-44d7-81bd-3882b783d0d5",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "Processing all datasets in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bbba92-799e-4490-92d2-21aa76282a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "import geopandas as gpd\n",
    "import warnings\n",
    "from shapely.geometry import shape, Point\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b586abad-1670-4e03-9a0d-2e88806064eb",
   "metadata": {},
   "source": [
    "### Collisions dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7344e3-7c79-422f-ad1b-514b813ca66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions = pd.read_csv(\"./original-data/collisions.csv\")\n",
    "\n",
    "print(collisions.columns)\n",
    "print(f\"Initial amount of rows: {len(collisions)}\")\n",
    "print(collisions.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdd2b8d-7a4d-471c-8579-95ee81bbe7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a CRASH DATETIME column as well as several checks to make sure we have the correct dataset\n",
    "\n",
    "# Truncating to the hour because some (most) rows are already truncated and we don't need more information\n",
    "collisions[\"CRASH DATETIME\"] = pd.to_datetime(collisions[\"CRASH DATE\"] + \" \" + collisions[\"CRASH TIME\"]).dt.floor(\"H\")\n",
    "\n",
    "# Adding day of week column\n",
    "collisions[\"CRASH WEEKDAY\"] = collisions[\"CRASH DATETIME\"].dt.day_name()\n",
    "\n",
    "# Adding BEFORE COVID column\n",
    "collisions[\"AFTER COVID\"] = collisions['CRASH DATETIME'].dt.year == 2020\n",
    "\n",
    "print(f\"First crash: {collisions['CRASH DATETIME'].sort_values().iloc[0]}\")\n",
    "\n",
    "print(f\"Last crash of 2018: {collisions[collisions['CRASH DATETIME'].dt.year == 2018]['CRASH DATETIME'].sort_values().iloc[-1]}\")\n",
    "\n",
    "print(f\"First crash of 2020: {collisions[collisions['CRASH DATETIME'].dt.year == 2020]['CRASH DATETIME'].sort_values().iloc[0]}\")\n",
    "\n",
    "print(f\"Last crash: {collisions['CRASH DATETIME'].sort_values().iloc[-1]}\")\n",
    "\n",
    "print(f\"Collisions in 2019: {len(collisions[collisions['CRASH DATETIME'].dt.year == 2019])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14873f1a-1acf-4515-a2fe-d3917de9596d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if LOCATION contains the same information as LATITUDE and LONGITUDE\n",
    "# We will take advantage of the fact that if a value is NaN in python then\n",
    "# value == value will return False\n",
    "def same_information():\n",
    "    location = collisions[\"LOCATION\"].tolist()\n",
    "    lat, lon = collisions[\"LATITUDE\"].tolist(), collisions[\"LONGITUDE\"].tolist()\n",
    "    for i, row in enumerate(location):\n",
    "        # LOCATION is not NaN\n",
    "        if row == row:\n",
    "            if not list(map(float, row[1: -1].split(\", \"))) == [lat[i], lon[i]]: return False\n",
    "        # LOCATION is NaN\n",
    "        else:\n",
    "            # If lat or lon is different to Nan return False\n",
    "            if lat[i] == lat[i] or lon[i] == lon[i]: return False\n",
    "    return True\n",
    "\n",
    "print(same_information())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c582293-d57b-4908-a9fd-8de6d749f968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column selection\n",
    "cols = [\n",
    "    \"CRASH DATETIME\",\n",
    "    \"CRASH WEEKDAY\",\n",
    "    \"AFTER COVID\",\n",
    "    \"BOROUGH\",\n",
    "    \"LATITUDE\",\n",
    "    \"LONGITUDE\",\n",
    "    \"NUMBER OF PERSONS INJURED\",\n",
    "    \"NUMBER OF PERSONS KILLED\",\n",
    "    \"VEHICLE TYPE CODE 1\",\n",
    "    \"CONTRIBUTING FACTOR VEHICLE 1\"\n",
    "]\n",
    "collisions = collisions[cols]\n",
    "\n",
    "# Number of missing values in each column\n",
    "print(collisions.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0815529a-4a93-4b33-ab6f-3b8c56e12fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in missing values with 0 for the injured/killed columns\n",
    "collisions[\"NUMBER OF PERSONS INJURED\"].fillna(0, inplace=True)\n",
    "collisions[\"NUMBER OF PERSONS KILLED\"].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988d9bd9-56d8-475e-9abb-e364eeaedfb3",
   "metadata": {},
   "source": [
    "We will now classify all vehicle types into these categories:\n",
    "* Ambulance\n",
    "* Bicycle\n",
    "* Car\n",
    "* E-bike\n",
    "* E-scooter\n",
    "* Truck\n",
    "* Bus\n",
    "* Motorcycle\n",
    "* Other\n",
    "* Unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30df9c6-e7d3-40d1-a2e0-7a4d83bc4869",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "classified_vehicles = {\n",
    "    \"Station Wagon/Sport Utility Vehicle\": \"Car\",\n",
    "    \"Sedan\": \"Car\",\n",
    "    \"Bus\": \"Bus\",\n",
    "    \"Tractor Truck Diesel\": \"Truck\",\n",
    "    \"Taxi\": \"Car\",\n",
    "    \"E-Scooter\": \"E-scooter\",\n",
    "    \"Flat Bed\": \"Truck\",\n",
    "    \"Motorbike\": \"Motorcycle\",\n",
    "    \"Motorcycle\": \"Motorcycle\",\n",
    "    \"Box Truck\": \"Truck\",\n",
    "    \"Pick-up Truck\": \"Truck\",\n",
    "    \"Bike\": \"Bicycle\",\n",
    "    \"Dump\": \"Truck\",\n",
    "    \"Concrete Mixer\": \"Truck\",\n",
    "    \"Van\": \"Truck\",\n",
    "    \"PK\": \"Other\",\n",
    "    \"Golf Cart\": \"Other\",\n",
    "    \"LIMO\": \"Car\",\n",
    "    \"Tanker\": \"Truck\",\n",
    "    \"AMBULANCE\": \"Ambulance\",\n",
    "    \"Convertible\": \"Car\",\n",
    "    \"E-Bike\": \"E-bike\",\n",
    "    \"Moped\": \"Motorcycle\",\n",
    "    \"Fire Truck\": \"Truck\",\n",
    "    \"nan\": \"Other\",\n",
    "    \"Tractor Truck Gasoline\": \"Truck\",\n",
    "    \"Ambulance\": \"Ambulance\",\n",
    "    \"forlift\": \"Other\",\n",
    "    \"MOTOR SKAT\": \"Other\",\n",
    "    \"FDNY LADDE\": \"Other\",\n",
    "    \"Tow Truck / Wrecker\": \"Truck\",\n",
    "    \"FIRE TRUCK\": \"Truck\",\n",
    "    \"PICK UP\": \"Other\",\n",
    "    \"Garbage or Refuse\": \"Truck\",\n",
    "    \"GARBAGE TR\": \"Truck\",\n",
    "    \"Chassis Cab\": \"Truck\",\n",
    "    \"Bulk Agriculture\": \"Other\",\n",
    "    \"Can\": \"Other\",\n",
    "    \"van\": \"Truck\",\n",
    "    \"Carry All\": \"Other\",\n",
    "    \"FLATBED FR\": \"Truck\",\n",
    "    \"Open Body\": \"Other\",\n",
    "    \"4 dr sedan\": \"Car\",\n",
    "    \"Motorscooter\": \"Motorcycle\",\n",
    "    \"Minibike\": \"Motorcycle\",\n",
    "    \"Flat Rack\": \"Other\",\n",
    "    \"Armored Truck\": \"Truck\",\n",
    "    \"School Bus\": \"Bus\",\n",
    "    \"FDNY TRUCK\": \"Truck\",\n",
    "    \"truck\": \"Truck\",\n",
    "    \"UNK\": \"Unknown\",\n",
    "    \"TRAILER\": \"Other\",\n",
    "    \"FIRTRUCK\": \"Truck\",\n",
    "    \"MOPED\": \"Motorcycle\",\n",
    "    \"Lift Boom\": \"Other\",\n",
    "    \"fdny ems\": \"Other\",\n",
    "    \"AMBULACE\": \"Ambulance\",\n",
    "    \"bus\": \"Bus\",\n",
    "    \"BOX TRUCK\": \"Truck\",\n",
    "    \"Street Swe\": \"Other\",\n",
    "    \"Scooter\": \"Motorcycle\",\n",
    "    \"FDNY fire\": \"Other\",\n",
    "    \"DELIVERY\": \"Other\",\n",
    "    \"Cement Tru\": \"Truck\",\n",
    "    \"USPS/GOVT\": \"Other\",\n",
    "    \"Pedicab\": \"Other\",\n",
    "    \"TRUCK VAN\": \"Truck\",\n",
    "    \"UTILITY\": \"Other\",\n",
    "    \"Pick up tr\": \"Other\",\n",
    "    \"UNKNOWN\": \"Unknown\",\n",
    "    \"Multi-Wheeled Vehicle\": \"Other\",\n",
    "    \"SUV\": \"Car\",\n",
    "    \"utility\": \"Other\",\n",
    "    \"POWER SHOV\": \"Other\",\n",
    "    \"DELIVERY T\": \"Other\",\n",
    "    \"SWT\": \"Other\",\n",
    "    \"Trac\": \"Other\",\n",
    "    \"FDNY AMBUL\": \"Ambulance\",\n",
    "    \"AMBU\": \"Other\",\n",
    "    \"USPS\": \"Other\",\n",
    "    \"FLAT\": \"Other\",\n",
    "    \"Beverage Truck\": \"Truck\",\n",
    "    \"E-BIKE\": \"E-bike\",\n",
    "    \"3-Door\": \"Car\",\n",
    "    \"Fork Lift\": \"Other\",\n",
    "    \"Refrigerated Van\": \"Truck\",\n",
    "    \"PSD\": \"Other\",\n",
    "    \"Fire Engin\": \"Other\",\n",
    "    \"FORKLIFT\": \"Other\",\n",
    "    \"TRAC\": \"Other\",\n",
    "    \"Tow Truck\": \"Truck\",\n",
    "    \"COURIER\": \"Other\",\n",
    "    \"Courier\": \"Other\",\n",
    "    \"Leased amb\": \"Other\",\n",
    "    \"SMART CAR\": \"Car\",\n",
    "    \"message si\": \"Other\",\n",
    "    \"scooter\": \"Motorcycle\",\n",
    "    \"E-UNICYCLE\": \"E-scooter\",\n",
    "    \"Street Cle\": \"Other\",\n",
    "    \"box\": \"Other\",\n",
    "    \"F550\": \"Truck\",\n",
    "    \"DELV\": \"Other\",\n",
    "    \"SKATEBOARD\": \"Other\",\n",
    "    \"Lawnmower\": \"Other\",\n",
    "    \"almbulance\": \"Other\",\n",
    "    \"dark color\": \"Other\",\n",
    "    \"Work Van\": \"Other\",\n",
    "    \"ford van\": \"Truck\",\n",
    "    \"ambulance\": \"Ambulance\",\n",
    "    \"Fire truck\": \"Truck\",\n",
    "    \"Minicycle\": \"Motorcycle\",\n",
    "    \"PC\": \"Other\",\n",
    "    \"box truck\": \"Truck\",\n",
    "    \"FDNY ENGIN\": \"Other\",\n",
    "    \"commercial\": \"Other\",\n",
    "    \"Unknown\": \"Unknown\",\n",
    "    \"Tractor tr\": \"Truck\",\n",
    "    \"2 dr sedan\": \"Car\",\n",
    "    \"FD LADDER\": \"Other\",\n",
    "    \"abulance\": \"Other\",\n",
    "    \"FDNY Engin\": \"Other\",\n",
    "    \"OTH\": \"Other\",\n",
    "    \"Go kart\": \"Other\",\n",
    "    \"Trailer\": \"Other\",\n",
    "    \"TRUCK\": \"Truck\",\n",
    "    \"Stake or Rack\": \"Other\",\n",
    "    \"COMMERCIAL\": \"Other\",\n",
    "    \"CHEVY EXPR\": \"Other\",\n",
    "    \"SLINGSHOT\": \"Other\",\n",
    "    \"dilevery t\": \"Other\",\n",
    "    \"FDNY #226\": \"Other\",\n",
    "    \"FREIGHT FL\": \"Other\",\n",
    "    \"Fork lift\": \"Other\",\n",
    "    \"UTIL\": \"Other\",\n",
    "    \"UNKN\": \"Other\",\n",
    "    \"FDNY FIRE\": \"Other\",\n",
    "    \"ELECTRIC S\": \"Other\",\n",
    "    \"FIRETRUCK\": \"Truck\",\n",
    "    \"MOVING VAN\": \"Truck\",\n",
    "    \"usps\": \"Other\",\n",
    "    \"moped\": \"Motorcycle\",\n",
    "    \"forklift\": \"Other\",\n",
    "    \"UPS TRUCK\": \"Truck\",\n",
    "    \"backhoe\": \"Other\",\n",
    "    \"Delv\": \"Other\",\n",
    "    \"dump truck\": \"Truck\",\n",
    "    \"Freight\": \"Other\",\n",
    "    \"Horse\": \"Other\",\n",
    "    \"Cargo Van\": \"Truck\",\n",
    "    \"USPS VAN\": \"Other\",\n",
    "    \"TRUCK FLAT\": \"Truck\",\n",
    "    \"BOBCAT FOR\": \"Other\",\n",
    "    \"Tractor Tr\": \"Truck\",\n",
    "    \"Pumper\": \"Other\",\n",
    "    \"DELIVERY V\": \"Other\",\n",
    "    \"DOT EQUIPM\": \"Other\",\n",
    "    \"fire truck\": \"Truck\",\n",
    "    \"Livestock Rack\": \"Other\",\n",
    "    \"GEN  AMBUL\": \"Ambulance\",\n",
    "    \"J1\": \"Other\",\n",
    "    \"DUMP\": \"Other\",\n",
    "    \"18 WHEELER\": \"Truck\",\n",
    "    \"MAIL TRUCK\": \"Other\",\n",
    "    \"UTILITY VE\": \"Other\",\n",
    "    \"MOTORSCOOT\": \"Motorcycle\",\n",
    "    \"government\": \"Other\",\n",
    "    \"trailer\": \"Other\",\n",
    "    \"FIRE ENGIN\": \"Other\",\n",
    "    \"Front-Load\": \"Other\",\n",
    "    \"DRILL RIG\": \"Other\",\n",
    "    \"SCOOTER\": \"Motorcycle\",\n",
    "    \"Wh Ford co\": \"Other\",\n",
    "    \"suburban\": \"Car\",\n",
    "    \"E REVEL SC\": \"Other\",\n",
    "    \"ROAD SWEEP\": \"Other\",\n",
    "    \"LIGHT TRAI\": \"Other\",\n",
    "    \"Tractor\": \"Truck\",\n",
    "    \"UT\": \"Other\",\n",
    "    \"USPS TRUCK\": \"Other\",\n",
    "    \"cross\": \"Other\",\n",
    "    \"Van Camper\": \"Other\",\n",
    "    \"AMBULENCE\": \"Ambulance\",\n",
    "    \"FOOD TRUCK\": \"Other\",\n",
    "    \"Bucket Tru\": \"Other\",\n",
    "    \"gator\": \"Other\",\n",
    "    \"FDNY Ambul\": \"Ambulance\",\n",
    "    \"JOHN DEERE\": \"Other\",\n",
    "    \"f-250\": \"Other\",\n",
    "    \"MECHANICAL\": \"Other\",\n",
    "    \"WORK VAN\": \"Other\",\n",
    "    \"NYC FD\": \"Other\",\n",
    "    \"MTA BUS\": \"Bus\",\n",
    "    \"NYC AMBULA\": \"Ambulance\",\n",
    "    \"GOLF CART\": \"Other\",\n",
    "    \"FLATBED\": \"Truck\",\n",
    "    \"Trc\": \"Other\",\n",
    "    \"FORK LIFT\": \"Other\",\n",
    "    \"Pick up Tr\": \"Other\",\n",
    "    \"postal bus\": \"Bus\",\n",
    "    \"F150XL PIC\": \"Other\",\n",
    "    \"ambu\": \"Other\",\n",
    "    \"Pick up\": \"Other\",\n",
    "    \"CAT\": \"Other\",\n",
    "    \"ELEC. UNIC\": \"E-scooter\",\n",
    "    \"1C\": \"Other\",\n",
    "    \"SCOOT\": \"Motorcycle\",\n",
    "    \"FREIG\": \"Other\",\n",
    "    \"AMBUL\": \"Ambulance\",\n",
    "    \"VAN T\": \"Other\",\n",
    "    \"MINI\": \"Other\",\n",
    "    \"Garba\": \"Other\",\n",
    "    \"motor\": \"Other\",\n",
    "    \"Lunch Wagon\": \"Other\",\n",
    "    \"E-Bik\": \"E-bike\",\n",
    "    \"Ambul\": \"Ambulance\",\n",
    "    \"FDNY\": \"Other\",\n",
    "    \"SCHOO\": \"Other\",\n",
    "    \"Comm\": \"Other\",\n",
    "    \"Fire\": \"Other\",\n",
    "    \"Sanit\": \"Other\",\n",
    "    \"mail\": \"Other\",\n",
    "    \"RV\": \"Other\",\n",
    "    \"GARBA\": \"Other\",\n",
    "    \"ambul\": \"Ambulance\",\n",
    "    \"FIRET\": \"Other\",\n",
    "    \"FIRE\": \"Other\",\n",
    "    \"SELF\": \"Other\",\n",
    "    \"STAK\": \"Other\",\n",
    "    \"WORKH\": \"Other\",\n",
    "    \"FORKL\": \"Other\",\n",
    "    \"Tract\": \"Other\",\n",
    "    \"freig\": \"Other\",\n",
    "    \"DELIV\": \"Other\",\n",
    "    \"trail\": \"Other\",\n",
    "    \"PICKU\": \"Other\",\n",
    "    \"Dumps\": \"Other\",\n",
    "    \"forkl\": \"Other\",\n",
    "    \"fire\": \"Other\",\n",
    "    \"TRK\": \"Other\",\n",
    "    \"ELECT\": \"Other\",\n",
    "    \"2- to\": \"Other\",\n",
    "    \"BROOM\": \"Other\",\n",
    "    \"TRAIL\": \"Other\",\n",
    "    \"EBIKE\": \"E-bike\",\n",
    "    \"Trail\": \"Other\",\n",
    "    \"Glass Rack\": \"Other\",\n",
    "    \"Motorized Home\": \"Other\",\n",
    "    \"US POSTAL\": \"Other\",\n",
    "    \"TRT\": \"Other\",\n",
    "    \"BLOCK\": \"Other\",\n",
    "    \"pas\": \"Other\",\n",
    "    \"COM\": \"Other\",\n",
    "    \"CONCR\": \"Other\",\n",
    "    \"Pallet\": \"Other\",\n",
    "    \"unknown\": \"Unknown\",\n",
    "    \"CHERR\": \"Other\",\n",
    "    \"UTV\": \"Other\",\n",
    "    \"MOTOR\": \"Other\",\n",
    "    \"MTA B\": \"Bus\",\n",
    "    \"TRACT\": \"Other\",\n",
    "    \"NYC\": \"Other\",\n",
    "    \"UHAUL\": \"Other\",\n",
    "    \"scoot\": \"Motorcycle\",\n",
    "    \"FED E\": \"Other\",\n",
    "    \"COMME\": \"Other\",\n",
    "    \"TRLR\": \"Other\",\n",
    "    \"LOADE\": \"Other\",\n",
    "    \"rv\": \"Other\",\n",
    "    \"TOWER\": \"Other\",\n",
    "    \"Pick\": \"Other\",\n",
    "    \"AMB\": \"Other\",\n",
    "    \"NS AM\": \"Other\",\n",
    "    \"UNKNO\": \"Unknown\",\n",
    "    \"NEW Y\": \"Other\",\n",
    "    \"TOW T\": \"Other\",\n",
    "    \"GRAY\": \"Other\",\n",
    "    \"tract\": \"Other\",\n",
    "    \"STREE\": \"Other\",\n",
    "    \"MAIL\": \"Other\",\n",
    "    \"e-bik\": \"E-bike\",\n",
    "    \"unk\": \"Unknown\",\n",
    "    \"box t\": \"Other\",\n",
    "    \"CRANE\": \"Other\",\n",
    "    \"garba\": \"Other\",\n",
    "    \"Pickup with mounted Camper\": \"Other\",\n",
    "    \"FRONT\": \"Other\",\n",
    "    \"Sprin\": \"Other\",\n",
    "    \"delv\": \"Other\",\n",
    "    \"POWER\": \"Other\",\n",
    "    \"Box t\": \"Other\",\n",
    "    \"CAMP\": \"Other\",\n",
    "    \"Enclosed Body - Removable Enclosure\": \"Other\",\n",
    "    \"RGS\": \"Other\",\n",
    "    \"GOVER\": \"Other\",\n",
    "    \"FORK\": \"Other\",\n",
    "    \"UTILI\": \"Other\",\n",
    "    \"POSTO\": \"Other\",\n",
    "    \"firet\": \"Other\",\n",
    "    \"WORK\": \"Other\",\n",
    "    \"R/V C\": \"Other\",\n",
    "    \"sgws\": \"Other\",\n",
    "    \"Cat 9\": \"Other\",\n",
    "    \"BACKH\": \"Other\",\n",
    "    \"E-MOT\": \"E-scooter\",\n",
    "    \"MACK\": \"Other\",\n",
    "    \"SPC\": \"Other\",\n",
    "    \"fork\": \"Other\",\n",
    "    \"OMR\": \"Other\",\n",
    "    \"semi\": \"Other\",\n",
    "    \"FORK-\": \"Other\",\n",
    "    \"Wheel\": \"Other\",\n",
    "    \"Utili\": \"Other\",\n",
    "    \"E-BIK\": \"E-bike\",\n",
    "    \"fd tr\": \"Other\",\n",
    "    \"SWEEP\": \"Other\",\n",
    "    \"BOX T\": \"Other\",\n",
    "    \"CASE\": \"Other\",\n",
    "    \"FD TR\": \"Other\",\n",
    "    \"Work\": \"Other\",\n",
    "    \"LIBER\": \"Other\",\n",
    "    \"fdny\": \"Other\",\n",
    "    \"COMB\": \"Other\",\n",
    "    \"HEAVY\": \"Other\",\n",
    "    \"DUMPS\": \"Other\",\n",
    "    \"MTA b\": \"Bus\",\n",
    "    \"Hopper\": \"Other\",\n",
    "    \"R/V\": \"Other\",\n",
    "    \"FOOD\": \"Other\",\n",
    "    \"FD tr\": \"Other\",\n",
    "    \"Spc\": \"Other\",\n",
    "    \"BED T\": \"Other\",\n",
    "    \"comme\": \"Other\",\n",
    "    \"UPS T\": \"Other\",\n",
    "    \"PAS\": \"Other\",\n",
    "    \"BICYC\": \"Bicycle\",\n",
    "    \"Subn\": \"Other\",\n",
    "    \"WHEEL\": \"Other\",\n",
    "    \"Util\": \"Other\",\n",
    "    \"ACCES\": \"Other\",\n",
    "    \"e sco\": \"E-scooter\",\n",
    "    \"BOBCA\": \"Other\",\n",
    "    \"TANK\": \"Other\",\n",
    "    \"TRACK\": \"Other\",\n",
    "    \"utili\": \"Other\",\n",
    "    \"DEMA-\": \"Other\",\n",
    "    \"tow\": \"Other\",\n",
    "    \"dump\": \"Other\",\n",
    "    \"Elect\": \"Other\",\n",
    "    \"deliv\": \"Other\",\n",
    "    \"Backh\": \"Other\",\n",
    "    \"CEMEN\": \"Other\",\n",
    "    \"99999\": \"Other\",\n",
    "    \"BULLD\": \"Other\",\n",
    "    \"seagr\": \"Other\",\n",
    "    \"schoo\": \"Other\",\n",
    "    \"CONST\": \"Other\",\n",
    "    \"self\": \"Other\",\n",
    "    \"BK\": \"Other\",\n",
    "    \"Semi\": \"Other\",\n",
    "    \"Scoot\": \"Motorcycle\",\n",
    "    \"NYPD\": \"Other\",\n",
    "    \"Taxis\": \"Car\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8991cdfa-5680-4a68-bae6-1696120271ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing vehicle types to classification we want to use, list is found in the \n",
    "#Â NYC collision dataset: ATV, bicycle, car/suv, ebike, E-scooter, truck/bus,\n",
    "# motorcycle, other, unknown\n",
    "\n",
    "collisions[\"ORIGINAL VEHICLE\"] = collisions[\"VEHICLE TYPE CODE 1\"].fillna(\"unknown\")\n",
    "collisions = collisions.drop(columns=\"VEHICLE TYPE CODE 1\")\n",
    "\n",
    "collisions[\"VEHICLE\"] = collisions[\"ORIGINAL VEHICLE\"].replace(classified_vehicles)\n",
    "\n",
    "collisions[\"VEHICLE\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions[\"CONTRIBUTING FACTOR VEHICLE 1\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_factors = {\n",
    "    \"Driver Inattention/Distraction\": \"Driver Inattention\",\n",
    "    \"Unspecified\": \"Unspecified\",\n",
    "    \"Following Too Closely\": \"Driving Infraction\",\n",
    "    \"Failure to Yield Right-of-Way\": \"Driving Infraction\",\n",
    "    \"Backing Unsafely\": \"Driving Infraction\",\n",
    "    \"Passing or Lane Usage Improper\": \"Driving Infraction\",\n",
    "    \"Passing Too Closely\": \"Driving Infraction\",\n",
    "    \"Other Vehicular\": \"Unspecified\",\n",
    "    \"Unsafe Lane Changing\": \"Driving Infraction\",\n",
    "    \"Turning Improperly\": \"Driving Infraction\",\n",
    "    \"Traffic Control Disregarded\": \"Driving Infraction\",\n",
    "    \"Unsafe Speed\": \"Driving Infraction\",\n",
    "    \"Driver Inexperience\": \"Driving Inexperience\",\n",
    "    \"Reaction to Uninvolved Vehicle\": \"Unspecified\",\n",
    "    \"Alcohol Involvement\": \"Substance Abuse\",\n",
    "    \"View Obstructed/Limited\": \"Environmental Factors\",\n",
    "    \"Pedestrian/Bicyclist/Other Pedestrian Error/Confusion\": \"Pedestrian Error\",\n",
    "    \"Oversized Vehicle\": \"Oversized Vehicle\",\n",
    "    \"Aggressive Driving/Road Rage\": \"Driving Behavior\",\n",
    "    \"Pavement Slippery\": \"Environmental Factors\",\n",
    "    \"Brakes Defective\": \"Vehicle Defect\",\n",
    "    \"Passenger Distraction\": \"Driver Inattention\",\n",
    "    \"Fell Asleep\": \"Medical Condition\",\n",
    "    \"Obstruction/Debris\": \"Environmental Factors\",\n",
    "    \"Outside Car Distraction\": \"Environmental Factors\",\n",
    "    \"Steering Failure\": \"Vehicle Defect\",\n",
    "    \"Tire Failure/Inadequate\": \"Vehicle Defect\",\n",
    "    \"Pavement Defective\": \"Environmental Factors\",\n",
    "    \"Glare\": \"Environmental Factors\",\n",
    "    \"Failure to Keep Right\": \"Driving Infraction\",\n",
    "    \"Illnes\": \"Medical Condition\",\n",
    "    \"Fatigued/Drowsy\": \"Medical Condition\",\n",
    "    \"Lost Consciousness\": \"Medical Condition\",\n",
    "    \"Driverless/Runaway Vehicle\": \"Driverless Vehicle\",\n",
    "    \"Drugs (illegal)\": \"Substance Abuse\",\n",
    "    \"Animals Action\": \"Environmental Factors\",\n",
    "    \"Accelerator Defective\": \"Vehicle Defect\",\n",
    "    \"Cell Phone (hand-Held)\": \"Driver Inattention\",\n",
    "    \"Lane Marking Improper/Inadequate\": \"Environmental Factors\",\n",
    "    \"Traffic Control Device Improper/Non-Working\": \"Environmental Factors\",\n",
    "    \"Physical Disability\": \"Medical Condition\",\n",
    "    \"Other Electronic Device\": \"Driver Inattention\",\n",
    "    \"Other Lighting Defects\": \"Vehicle Defect\",\n",
    "    \"Vehicle Vandalism\": \"Unspecified\",\n",
    "    \"Prescription Medication\": \"Medical Condition\",\n",
    "    \"Tinted Windows\": \"Vehicle Defect\",\n",
    "    \"Eating or Drinking\": \"Driver Inattention\",\n",
    "    \"Shoulders Defective/Improper\": \"Vehicle Defect\",\n",
    "    \"Headlights Defective\": \"Vehicle Defect\",\n",
    "    \"Using On Board Navigation Device\": \"Driver Inattention\",\n",
    "    \"Cell Phone (hands-free)\": \"Driver Inattention\",\n",
    "    \"Tow Hitch Defective\": \"Vehicle Defect\",\n",
    "    \"Windshield Inadequate\": \"Vehicle Defect\",\n",
    "    \"Texting\": \"Driver Inattention\",\n",
    "    \"Listening/Using Headphones\": \"Driver Inattention\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions[\"ORIGINAL FACTOR\"] = collisions[\"CONTRIBUTING FACTOR VEHICLE 1\"].fillna(\"Unspecified\")\n",
    "collisions = collisions.drop(columns= \"CONTRIBUTING FACTOR VEHICLE 1\")\n",
    "\n",
    "collisions[\"FACTOR\"] = collisions[\"ORIGINAL FACTOR\"].replace(classified_factors)\n",
    "\n",
    "collisions[\"FACTOR\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d4f2f6-10d3-4066-b300-8688af84fbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing LATITUDE and longitude values that don't make make sense for NYC into NaNs\n",
    "collisions[\"LATITUDE\"] = collisions[\"LATITUDE\"].where(collisions[\"LATITUDE\"].between(38, 42))\n",
    "collisions[\"LONGITUDE\"] = collisions[\"LONGITUDE\"].where(collisions[\"LONGITUDE\"].between(-76, -72))\n",
    "\n",
    "# Adding our own LOCATION column, we do know that it already exists but it was easier for us this way\n",
    "# If either LATITUDE or LONGITUDE is NaN then location will be NaN\n",
    "def combine_columns(row):\n",
    "    if pd.notna(row[\"LATITUDE\"]) and pd.notna(row[\"LONGITUDE\"]):\n",
    "        return [row[\"LATITUDE\"], row[\"LONGITUDE\"]]\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "collisions[\"LOCATION\"] = collisions.apply(combine_columns, axis=1)\n",
    "\n",
    "# Dropping NaNs in LOCATION and BOROUGH, if either BOROUGH or LOCATION is not NaN we will keep the row\n",
    "collisions.dropna(subset=[\"LOCATION\", \"BOROUGH\"], how=\"all\", inplace=True)\n",
    "\n",
    "print(f\"Current amount of rows: {len(collisions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbea8c6-1c9d-4fc5-a868-27e3b0761420",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(collisions.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbafc66b-d2de-43da-a276-5ef2cfddaf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7963d987-2f34-4784-8a76-3f47a1ea62db",
   "metadata": {},
   "source": [
    "### Weather dataset\n",
    "\n",
    "Data obtained from the ASOS Network of Iowa State University, with the following link: https://mesonet.agron.iastate.edu/request/download.phtml?network=NY_ASOS. <br>\n",
    "\n",
    "We have selected the station [NYC] NEW YORK CITY (1943-Now).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a2acc0-441c-459b-8d2f-12b7d05d14a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the csv file into a pandas DataFrame\n",
    "weather_2018 = pd.read_csv(\"./original-data/NYC_weather_2018.csv\")\n",
    "weather_2020 = pd.read_csv(\"./original-data/NYC_weather_2020.csv\")\n",
    "\n",
    "# concatenate the two dataframes\n",
    "weather = pd.concat([weather_2018, weather_2020], ignore_index=True)\n",
    "\n",
    "# M & T represents a NaN in the dataset (found in the docs)\n",
    "weather = weather.replace('M', None).replace('T', None)\n",
    "\n",
    "# print the concatenated dataframe\n",
    "print(weather.columns)\n",
    "\n",
    "# na values in the dataframe\n",
    "print(weather.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following columns will be removed, as they are not deemed relevant. This may be due to the focus on summer data, where columns related to snow lack significance, or because the columns inherently possess a high number of missing values: <br>\n",
    "- station\n",
    "- dwpf\n",
    "- drct\n",
    "- alti\n",
    "- gust\n",
    "- skyc1\n",
    "- skyc2\n",
    "- skyc3\n",
    "- skyc4\n",
    "- sky1\n",
    "- skyl2\n",
    "- skyl3\n",
    "- skyl4\n",
    "- wxcodes\n",
    "- feel\n",
    "- ice_accretion_1hr\n",
    "- ice_accretion_3hr\n",
    "- ice_accretion_6hr\n",
    "- peak_wind_gust\n",
    "- peak_wind_drct\n",
    "- peak_wind_time\n",
    "- metar\n",
    "- snowdepth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    \"valid\",\n",
    "    \"tmpf\",\n",
    "    \"relh\",\n",
    "    \"sknt\",\n",
    "    \"p01i\",\n",
    "    \"mslp\",\n",
    "    \"vsby\",\n",
    "]\n",
    "\n",
    "weather = weather[cols]\n",
    "\n",
    "weather[cols[1:]] = weather[cols[1:]].apply(pd.to_numeric)\n",
    "\n",
    "print(weather.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The analysis will involve working with the following variables.\n",
    "- **`valid`**: timestamp of the observation\n",
    "- **`tmpf`**: Air Temperature in Fahrenheit, typically @ 2 meters \n",
    "- **`relh`**: Relative Humidity in %\n",
    "- **`sknt`**: Wind Speed in knots \n",
    "- **`p01i`**: One hour precipitation for the period from the observation time to the time of the previous hourly precipitation reset. Values are in inches.\n",
    "- **`mslp`**: Sea Level Pressure in millibar \n",
    "- **`vsby`**: Visibility in miles "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visually explore the missing values using the `missingno` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "\n",
    "# matrix plot\n",
    "msno.matrix(weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `msno.matrix(weather)` generates a nullity matrix, which is a graphical representation of the absence of data in the `weather` DataFrame. Each row in the matrix corresponds to a row in the DataFrame, and white marks indicate missing values.\n",
    "\n",
    "By observing the graph, you can look for patterns in the missing data. For instance, if you notice that white marks tend to cluster in certain areas, it could suggest that the missing data is not randomly distributed but rather related to some variable or condition. As in the case of the `sknt` column, likely due to a failure in the wind speed sensor, we should take this into account when analyzing the data.\n",
    "\n",
    "We can also visually see that missing values in the `tmpf` and `relh` columns are related.\n",
    "\n",
    "Another valuable insight from this graph is that the `mslp` column may not be as interesting as initially thought, as having so many random missing values doesn't make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap\n",
    "msno.heatmap(weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `msno.heatmap(weather)` function generates a heatmap showing the correlation of missing data in the `weather` DataFrame. The values on the heatmap range from -1 to 1.\n",
    "\n",
    "A value close to 1 indicates that the presence of a missing value in one column is strongly correlated with the presence of a missing value in another column. This could suggest that missing values in both columns are being caused by the same underlying factor.\n",
    "\n",
    "On the other hand, a value close to -1 indicates that the presence of a missing value in one column is strongly correlated with the presence of a value in another column. This could suggest that missing values in one column are being caused by the absence of missing values in the other column.\n",
    "\n",
    "Now, we can confirm the strong correlation between the missing values in the `tmpf` and `relh` columns, as well as the significant correlation between these columns and `vsby`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the columns mslp\n",
    "weather.drop('mslp', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's determine the intervals where the wind speed sensor may have stopped functioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the weather dataframe to show only data from September 2018\n",
    "weather_sep2018 = weather[(weather['valid'] >= '2018-09-01') & (weather['valid'] < '2018-09-30')]\n",
    "\n",
    "# create a mask for missing values in sknt column\n",
    "mask = weather_sep2018['sknt'].isna()\n",
    "\n",
    "# create a group identifier for consecutive missing values\n",
    "group_id = (~mask).cumsum()\n",
    "\n",
    "# group the consecutive missing values together and count the number of missing values in each group\n",
    "consecutive_missing_values = mask.groupby(group_id).sum()\n",
    "\n",
    "# print the number of consecutive missing values and the last one in the series\n",
    "print(f\"Number of consecutive missing values in sknt: {consecutive_missing_values.max()}\")\n",
    "\n",
    "# obtain the first and last element with id = consecutive_missing_values.idxmax() in group_id\n",
    "group_id_max = consecutive_missing_values.idxmax()\n",
    "\n",
    "first_element_valid_sep2018 = weather_sep2018.loc[group_id.eq(group_id_max).idxmax(), 'valid']\n",
    "last_element_valid_sep2018 = weather_sep2018.loc[group_id.eq(group_id_max+1).idxmax(), 'valid']\n",
    "\n",
    "# print the valid column of the first and last element of the consecutive missing value\n",
    "print(f\"Valid column of the first element: {first_element_valid_sep2018}\")\n",
    "print(f\"Valid column of the last element: {last_element_valid_sep2018}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the weather dataframe to show only data from June 2020\n",
    "weather_jun2020 = weather[(weather['valid'] >= '2020-06-01') & (weather['valid'] < '2020-06-30')]\n",
    "\n",
    "# create a mask for missing values in sknt column\n",
    "mask = weather_jun2020['sknt'].isna()\n",
    "\n",
    "# create a group identifier for consecutive missing values\n",
    "group_id = (~mask).cumsum()\n",
    "\n",
    "# group the consecutive missing values together and count the number of missing values in each group\n",
    "consecutive_missing_values = mask.groupby(group_id).sum()\n",
    "\n",
    "# print the number of consecutive missing values and the last one in the series\n",
    "print(f\"Number of consecutive missing values in sknt: {consecutive_missing_values.max()}\")\n",
    "\n",
    "# obtain the first and last element with id = consecutive_missing_values.idxmax() in group_id\n",
    "group_id_max = consecutive_missing_values.idxmax()\n",
    "first_element_valid_jun2020 = weather_jun2020.loc[group_id.eq(group_id_max).idxmax(), 'valid']\n",
    "last_element_valid_jun2020 = weather_jun2020.loc[group_id.eq(group_id_max+1).idxmax(), 'valid']\n",
    "\n",
    "# print the valid column of the first and last element of the consecutive missing value\n",
    "print(f\"Valid column of the first element: {first_element_valid_jun2020}\")\n",
    "print(f\"Valid column of the last element: {last_element_valid_jun2020}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the identified periods of wind speed sensor malfunction, a procedure is initiated to interpolate all remaining missing values, excluding those specific intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate the missing values in sknt column except the ones between 2020-06-01 00:51 and 2020-06-19 19:51 and between 2018-09-12 14:21 and 2018-09-17 17:51\n",
    "mask1 = (weather['valid'] >= first_element_valid_jun2020) & (weather['valid'] <= last_element_valid_jun2020)\n",
    "mask2 = (weather['valid'] >= first_element_valid_sep2018) & (weather['valid'] <= last_element_valid_sep2018)\n",
    "mask = ~(mask1 | mask2)\n",
    "weather.loc[mask, 'sknt'] = weather.loc[mask, 'sknt'].interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the analysis of the `p01i` column, a visualization is conducted on the values preceding missing entries. This aims to provide an approximate understanding of their magnitudes. Considering the uncertainty about sensor behavior, it is plausible that the sensor may cease recording during periods of no rainfall or excessively high rainfall amounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the rows where the value in the p01i column is not missing and the value in the shifted p01i column is missing\n",
    "before_missing = weather.loc[weather['p01i'].notna() & weather['p01i'].shift(1).isna()]\n",
    "\n",
    "ch = alt.Chart(before_missing).mark_bar().encode(\n",
    "    x='valid:O',\n",
    "    y='p01i:Q'\n",
    ")\n",
    "\n",
    "ch.properties(\n",
    "    width=800,\n",
    "    height=400\n",
    ").configure_axisX(labels=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Statistics of weather['p01i']:\\n\", weather['p01i'].describe())\n",
    "print(\"\\nStatistics of before_missing['p01i']:\\n\", before_missing['p01i'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No specific patterns or behaviors in the sensor data have been identified. Consequently, a decision has been made to interpolate the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate the missing values in p01i column\n",
    "weather['p01i'] = weather['p01i'].interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previously mentioned, there exists a correlation between the missing values in the `vsby` column and `tmpf`. Consequently, the decision has been made to interpolate only the values that are not correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate the missing valurs in vsby column\n",
    "weather.loc[weather['tmpf'].notna(), 'vsby'] = weather.loc[weather['tmpf'].notna(), 'vsby'].interpolate()\n",
    "\n",
    "# get the count of missing values in each column\n",
    "weather.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the conversion to the International System of Units will be performed:\n",
    "- **tmpf**: Fahrenheit to Celsius <br>\n",
    "$$ Celsius = (Fahrenheit - 32) \\cdot  \\frac{5}{9} $$ \n",
    "- **sknt**: Knots to km/h\n",
    "$$ 1 \\ knot = 1.852 \\ \\frac{km}{h}$$\n",
    "- **p01i**: inches to cm\n",
    "$$ 1 \\ inch  = 2.54 \\ cm $$\n",
    "- **vsby**: miles to km\n",
    "$$ 1 \\ mile = 1.609344 \\ km $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather[\"tmpf\"] = (weather[\"tmpf\"] - 32) * 5/9\n",
    "\n",
    "weather['sknt'] = weather['sknt'] * 1.852\n",
    "\n",
    "weather['p01i'] = weather['p01i'] * 2.54\n",
    "\n",
    "weather['vsby'] = weather['vsby'] * 1.609344\n",
    "\n",
    "\n",
    "weather['valid'] = pd.to_datetime(weather['valid']).dt.floor('H')\n",
    "weather_grouped = weather.groupby('valid').mean().reset_index()\n",
    "print(weather_grouped.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"First weather: {weather_grouped['valid'].sort_values().iloc[0]}\")\n",
    "\n",
    "print(f\"Last weather of 2018: {weather_grouped[weather_grouped['valid'].dt.year == 2018]['valid'].sort_values().iloc[-1]}\")\n",
    "\n",
    "print(f\"First weather of 2020: {weather_grouped[weather_grouped['valid'].dt.year == 2020]['valid'].sort_values().iloc[0]}\")\n",
    "\n",
    "print(f\"Last weather: {weather_grouped['valid'].sort_values().iloc[-1]}\")\n",
    "\n",
    "print(f\"Weather in 2019: {len(weather_grouped[weather_grouped['valid'].dt.year == 2019])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.describe()\n",
    "\n",
    "weather_grouped.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions = collisions.merge(weather_grouped, how=\"outer\", right_on=\"valid\", left_on=\"CRASH DATETIME\")\n",
    "collisions.drop(columns=\"valid\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45435d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f8612e",
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions[\"LOCATION\"].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33cbfff-7e7d-4959-96de-df8dab85f1de",
   "metadata": {},
   "source": [
    "### NYC Map\n",
    "Currently using [NYC community district boundaries](https://data.cityofnewyork.us/City-Government/Community-Districts/yfnk-k7r4) in a geojson format. Lets add the number of collisions in each region. We find that community districts is the perfect granularity for a choropleth map. Not too little (Boroughs) not too much (zip codes). Check NYC total area [here](https://en.wikipedia.org/wiki/New_York_City#Geography)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8e0ca5-a120-46b4-aeba-1046e4d7bb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_data = gpd.read_file(f\"./original-data/map.geojson\")\n",
    "\n",
    "collisions[\"DISTRICT\"] = collisions[\"LOCATION\"].apply(\n",
    "    lambda x: [-1] if x != x else np.where(map_data.contains(Point(x[1], x[0])))[0]\n",
    ")\n",
    "\n",
    "collisions[\"DISTRICT\"] = collisions[\"DISTRICT\"].apply(lambda x: -1 if len(x) == 0 else x[0]).replace(-1, np.nan)\n",
    "\n",
    "map_data[\"COLLISIONS\"] = collisions.groupby([\"DISTRICT\"]).size()\n",
    "\n",
    "map_data[\"AREA\"] = map_data[\"geometry\"].area\n",
    "\n",
    "map_data[\"AREA PROPORTION\"] = map_data[\"AREA\"] / map_data[\"AREA\"].sum()\n",
    "\n",
    "# Value found online (wikipedia)\n",
    "map_data[\"AREA KM2\"] = 783.84 * map_data[\"AREA PROPORTION\"]\n",
    "\n",
    "map_data[\"COLLISIONS / KM2\"] = map_data[\"COLLISIONS\"] / map_data[\"AREA KM2\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions.to_csv(\"./processed-data/collisions.csv\", index=False)\n",
    "weather_grouped.to_csv(\"processed-data/weather.csv\", index=False)\n",
    "map_data.to_file(\"processed-data/map.geojson\", driver=\"GeoJSON\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
