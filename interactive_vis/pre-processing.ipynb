{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI: Second Practical Work\n",
    "\n",
    "**Authors:** Gerard Comas & Marc Franquesa.\n",
    "\n",
    "**COLAB INSTRUCTIONS:**\n",
    "1. Upload notebooks\n",
    "2. Create `original-data` and `processed-data` folders\n",
    "3. Upload datasets found in local `original-data` to colab `original-data`\n",
    "4. Execute `pre-processing.ipynb` notebook\n",
    "5. Execute `design.ipynb` notebook\n",
    "\n",
    "In order to make our enitre visualisation coherent and work well with one another, we have only kepts collisions made by the vehicles noted in the project statement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If False will fill dataset\n",
    "# Not needed anymore as we have found\n",
    "# workarounds for every plot\n",
    "\n",
    "using_colab_or_streamlit = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "Processing all datasets in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import warnings\n",
    "from shapely.geometry import shape, Point\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collisions dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the dataset\n",
    "collisions = pd.read_csv(\"./original-data/collisions.csv\")\n",
    "collisions[\"CRASH DATETIME\"] = pd.to_datetime(collisions[\"CRASH DATETIME\"])\n",
    "\n",
    "collisions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only the values from 2018\n",
    "collisions = collisions[collisions[\"CRASH DATETIME\"] < \"2019-01-01\"] \n",
    "\n",
    "# select only the columns we need\n",
    "collisions = collisions[[\"CRASH DATETIME\", \"LATITUDE\", \"LONGITUDE\", \"ORIGINAL VEHICLE\", \"NUMBER OF PERSONS INJURED\", \"NUMBER OF PERSONS KILLED\", \"ORIGINAL FACTOR\", \"FACTOR\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {\n",
    "    \"Taxi\": [\"Taxi\"],\n",
    "    \"Ambulance\": [\"Ambulance\", \"AMBUL\", \"Ambul\", \"ambul\", \"AMB\", \"AMBU\", \"AMBULANCE\"],\n",
    "    \"Fire truck\": [\"Fire\", \"FIRET\", \"FIRE\", \"FDNY\", \"fdny\", \"FD tr\", \"fd tr\", \"firet\", \"fire\"],\n",
    "}\n",
    "\n",
    "reverse_categories = {val: key for key, values in categories.items() for val in values}\n",
    "\n",
    "# Assume df is your DataFrame and 'column_name' is the column you want to classify\n",
    "collisions[\"VEHICLE\"] = collisions[\"ORIGINAL VEHICLE\"].map(reverse_categories)\n",
    "\n",
    "collisions = collisions.dropna(subset=[\"VEHICLE\"])\n",
    "\n",
    "collisions = collisions[[\"CRASH DATETIME\", \"LATITUDE\", \"LONGITUDE\", \"VEHICLE\", \"NUMBER OF PERSONS INJURED\", \"NUMBER OF PERSONS KILLED\", \"ORIGINAL FACTOR\", \"FACTOR\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets add emojis\n",
    "vehicle_emojis = {\n",
    "    \"Taxi\": \"ðŸš•\",\n",
    "    \"Ambulance\": \"ðŸš‘\",\n",
    "    \"Fire truck\": \"ðŸš’\",\n",
    "}\n",
    "\n",
    "collisions[\"VEHICLE EMOJI\"] = collisions[\"VEHICLE\"].map(vehicle_emojis)\n",
    "\n",
    "collisions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add day information\n",
    "collisions[\"CRASH DAY\"] = collisions[\"CRASH DATETIME\"].dt.strftime(\"%Y-%m-%d\")\n",
    "collisions[\"CRASH WEEKDAY\"] = collisions[\"CRASH DATETIME\"].dt.day_name()\n",
    "collisions[\"CRASH WEEK NUMBER\"] = collisions[\"CRASH DATETIME\"].dt.isocalendar().week\n",
    "collisions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv(\"./original-data/weather2018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = weather[[\"datetime\", \"icon\"]]\n",
    "weather[\"WEATHER\"] = weather[\"icon\"]\n",
    "weather[\"WEATHER\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_emojis = {\n",
    "    \"rain\" : \"ðŸŒ§\",\n",
    "    \"clear-day\" : \"â˜€ï¸\",\n",
    "    \"cloudy\" : \"â˜ï¸\",\n",
    "    \"partly-cloudy-day\" : \"â›…ï¸\",\n",
    "}\n",
    "\n",
    "weather[\"WEATHER EMOJI\"] = weather[\"WEATHER\"].map(weather_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collisions + Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the collisions and weather dataframes on the \"CRASH DAY\" and \"datetime\" columns\n",
    "collisions_weather = pd.merge(collisions, weather, left_on=\"CRASH DAY\", right_on=\"datetime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NY Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_data = gpd.read_file(f\"./original-data/map.geojson\")\n",
    "\n",
    "collisions_weather[\"BOROUGH\"] = collisions_weather.apply(lambda x: [-1] if pd.isnull(x[\"LATITUDE\"]) or pd.isnull(x[\"LONGITUDE\"]) else np.where(map_data.contains(Point(x[\"LONGITUDE\"], x[\"LATITUDE\"])))[0], axis=1)\n",
    "\n",
    "collisions_weather[\"BOROUGH\"] = collisions_weather[\"BOROUGH\"].apply(lambda x: -1 if len(x) == 0 else x[0]).replace(-1, np.nan)\n",
    "\n",
    "collisions_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_data[\"COLLISIONS\"] = collisions_weather.groupby([\"BOROUGH\"]).size()\n",
    "\n",
    "map_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boroughs = {\n",
    "    0.0: \"Staten Island\",\n",
    "    1.0: \"Bronx\",\n",
    "    2.0: \"Queens\",\n",
    "    3.0: \"Manhattan\",\n",
    "    4.0: \"Brooklyn\"\n",
    "}\n",
    "\n",
    "collisions_weather[\"BOROUGH\"] = collisions_weather[\"BOROUGH\"].map(boroughs)\n",
    "\n",
    "collisions_weather = collisions_weather[[\"CRASH DATETIME\", \"CRASH DAY\", \"CRASH WEEK NUMBER\", \"CRASH WEEKDAY\", \"BOROUGH\", \"VEHICLE\", \"VEHICLE EMOJI\", \"WEATHER\", \"WEATHER EMOJI\", \"NUMBER OF PERSONS INJURED\", \"NUMBER OF PERSONS KILLED\", \"ORIGINAL FACTOR\", \"FACTOR\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to epsh = 4326\n",
    "# map_data[\"geometry\"] = map_data[\"geometry\"].to_crs(epsg=4326)\n",
    "\n",
    "map_data[\"AREA\"] = map_data[\"geometry\"].area\n",
    "\n",
    "map_data[\"AREA PROPORTION\"] = map_data[\"AREA\"] / map_data[\"AREA\"].sum()\n",
    "\n",
    "# Value found online (wikipedia)\n",
    "map_data[\"AREA KM2\"] = 783.84 * map_data[\"AREA PROPORTION\"]\n",
    "\n",
    "map_data[\"COLLISIONS / KM2\"] = map_data[\"COLLISIONS\"] / map_data[\"AREA KM2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_data[\"BOROUGH\"] = map_data[\"boro_name\"]\n",
    "map_data[\"AREA_KM2\"] = map_data[\"AREA KM2\"]\n",
    "\n",
    "map_data = map_data[[\"BOROUGH\", \"AREA_KM2\", \"COLLISIONS\", \"COLLISIONS / KM2\", \"geometry\"]]\n",
    "\n",
    "map_data.to_file(\"processed-data/map.geojson\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling with empty values\n",
    "\n",
    "We will now fill the data set so we have values for all combination of day - vehicle - weather - borough so that our plots have sensible values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = collisions_weather[[\"CRASH DATETIME\", \"CRASH DAY\", \"CRASH WEEK NUMBER\", \"CRASH WEEKDAY\"]]\n",
    "dates[\"CRASH DATETIME\"] = dates[\"CRASH DATETIME\"].dt.floor(\"D\")\n",
    "dates = dates.drop_duplicates()\n",
    "dates[\"key\"] = 0\n",
    "\n",
    "hours = pd.DataFrame({\"HOUR\": range(0, 24)})\n",
    "hours[\"key\"] = 0\n",
    "\n",
    "boroughs = collisions_weather[[\"BOROUGH\"]].drop_duplicates().dropna()\n",
    "boroughs[\"key\"] = 0\n",
    "\n",
    "vehicles = collisions_weather[[\"VEHICLE\", \"VEHICLE EMOJI\"]].drop_duplicates().dropna()\n",
    "vehicles[\"key\"] = 0\n",
    "\n",
    "weathers = collisions_weather[[\"WEATHER\", \"WEATHER EMOJI\"]].drop_duplicates().dropna()\n",
    "weathers[\"key\"] = 0\n",
    "\n",
    "filler = (\n",
    "    dates\n",
    "    .merge(boroughs, on=\"key\")\n",
    "    .merge(vehicles, on=\"key\")\n",
    "    .merge(weathers, on=\"key\")\n",
    "    .merge(hours, on=\"key\")\n",
    "    .drop(columns=[\"key\"])\n",
    ")\n",
    "\n",
    "filler[\"VALID\"] = 0\n",
    "\n",
    "filler.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions_weather.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions_weather[\"HOUR\"] = collisions_weather[\"CRASH DATETIME\"].dt.hour\n",
    "collisions_weather[\"VALID\"] = 1\n",
    "\n",
    "if not using_colab_or_streamlit:\n",
    "    collisions_weather = pd.concat([collisions_weather, filler])\n",
    "\n",
    "collisions_weather[\"MONTH\"] = collisions_weather[\"CRASH DATETIME\"].dt.strftime(\"%B\")\n",
    "collisions_weather[\"DAY\"] = collisions_weather[\"CRASH DATETIME\"].dt.strftime(\"%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some final details\n",
    "Mapping some names to make nicer plots. Could have been put in design but decided to set any dataframe formatting here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_weekdays = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "\n",
    "new_weekdays = [\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"]\n",
    "\n",
    "collisions_weather[\"CRASH WEEKDAY\"] = collisions_weather[\"CRASH WEEKDAY\"].map(dict(zip(old_weekdays, new_weekdays)))\n",
    "\n",
    "collisions_weather[\"CRASH HOUR\"] = collisions_weather[\"CRASH DATETIME\"].dt.strftime(\"%H\") + \":00H\"\n",
    "\n",
    "collisions_weather[\"LOCATION AT HOUR\"] = collisions_weather[\"BOROUGH\"] + \", \" + collisions_weather[\"CRASH HOUR\"]\n",
    "\n",
    "old_weather = [\"rain\", \"clear-day\", \"cloudy\", \"partly-cloudy-day\"]\n",
    "\n",
    "new_weather = [\"Rainy\", \"Clear\", \"Cloudy\", \"Partly cloudy\"]\n",
    "\n",
    "collisions_weather[\"WEATHER\"] = collisions_weather[\"WEATHER\"].map(dict(zip(old_weather, new_weather)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions_weather.to_csv(\"./processed-data/collisions_weather.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
